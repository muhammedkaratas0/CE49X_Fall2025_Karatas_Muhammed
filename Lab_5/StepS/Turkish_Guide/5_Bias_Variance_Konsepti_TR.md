# Bias-Variance Tradeoff (Ã–dÃ¼nleÅŸim) - Lab 5'in Ana Konusu

**Ã–ÄŸrenci:** Muhammed Ali KarataÅŸ (2021403030)
**Tarih:** 12 KasÄ±m 2025

---

## ğŸ¯ Bu Lab'Ä±n ASIL Konusu Budur!

Bias-Variance Tradeoff, **makine Ã¶ÄŸrenmesinin en temel konseptlerinden biri**dir. Lab 5'in tÃ¼m amacÄ± bunu anlamaktÄ±r!

---

## ğŸ¤” Basit Soru: Model Ne Kadar KarmaÅŸÄ±k OlmalÄ±?

### SeÃ§enekler

**SeÃ§enek 1:** Ã‡ok basit model (degree 1)
**SeÃ§enek 2:** Orta karmaÅŸÄ±klÄ±k (degree 5)
**SeÃ§enek 3:** Ã‡ok karmaÅŸÄ±k (degree 10)

**Hangisi en iyi?** Ä°ÅŸte bu sorunun cevabÄ± **Bias-Variance Tradeoff**!

---

## ğŸ“š ÃœÃ§ Durum: Goldilocks Hikayesi

### 1. Underfitting (Ã‡ok Basit) - "Ã‡ok SoÄŸuk" ğŸ¥¶

**Ne oluyor?**
- Model **Ã§ok basit**
- Verilerdeki iliÅŸkileri **yakalayamÄ±yor**
- Hem eÄŸitimde hem testte **baÅŸarÄ±sÄ±z**

**Lab 5'te:**
```
Degree 1 (Linear):
CO = Î²â‚€ + Î²â‚Ã—T + Î²â‚‚Ã—RH + Î²â‚ƒÃ—AH

EÄŸitim HatasÄ±: 2.04 (yÃ¼ksek!)
Test HatasÄ±:    2.06 (yÃ¼ksek!)
```

**Analoji - SÄ±nav:**
```
Ã–ÄŸrenci: Konuyu hiÃ§ anlamadÄ±
Ders Ã§alÄ±ÅŸÄ±rken: %60 doÄŸru
SÄ±navda: %58 doÄŸru

Her iki skorda da kÃ¶tÃ¼ â†’ Underfitting!
```

**GÃ¶rsel:**
```
CO â†‘
   |    Ã—
   |      Ã—  Ã—    â† Noktalar (gerÃ§ek veri)
   |  Ã— /    Ã—  Ã—
   |   /Ã—      Ã—   â† DÃ¼z Ã§izgi (model)
   |/_____________â†’ T

Model Ã§ok basit! EÄŸriyi yakalayamÄ±yor!
```

### 2. Just Right (Tam OlmalÄ±) - "Tam KararÄ±nda" âœ¨

**Ne oluyor?**
- Model **dengeli**
- Ã–nemli iliÅŸkileri **yakalÄ±yor**
- GÃ¼rÃ¼ltÃ¼ye takÄ±lmÄ±yor
- **En iyi genelleme**!

**Lab 5'te:**
```
Degree 9 (Optimal):
Daha karmaÅŸÄ±k formÃ¼l...

EÄŸitim HatasÄ±: 1.95 (dÃ¼ÅŸÃ¼k!)
Test HatasÄ±:    1.98 (en dÃ¼ÅŸÃ¼k!)
Gap:            0.03 (kÃ¼Ã§Ã¼k!)
```

**Analoji - SÄ±nav:**
```
Ã–ÄŸrenci: Konuyu iyi Ã¶ÄŸrendi
Ders Ã§alÄ±ÅŸÄ±rken: %85 doÄŸru
SÄ±navda: %82 doÄŸru

Her ikisi de iyi, yakÄ±n skor â†’ Good fit!
```

**GÃ¶rsel:**
```
CO â†‘
   |    Ã—
   |   ~~~Ã—~~    â† Noktalar
   |  Ã—~~  Ã—~~Ã—
   |  ~~Ã—   ~~Ã—  â† EÄŸri (model)
   |/_____________â†’ T

Model deseni yakalÄ±yor, gÃ¼rÃ¼ltÃ¼yÃ¼ deÄŸil!
```

### 3. Overfitting (Ã‡ok KarmaÅŸÄ±k) - "Ã‡ok SÄ±cak" ğŸ”¥

**Ne oluyor?**
- Model **Ã§ok karmaÅŸÄ±k**
- EÄŸitim verisini **ezberliyor**
- GÃ¼rÃ¼ltÃ¼yÃ¼ bile Ã¶ÄŸreniyor!
- Yeni verilerle **baÅŸarÄ±sÄ±z**

**Lab 5'te:**
```
Degree 10 (Overfit):
CO = Î²â‚€ + ... + 364 terim!

EÄŸitim HatasÄ±: 1.94 (Ã§ok dÃ¼ÅŸÃ¼k!)
Test HatasÄ±:    1.99 (arttÄ±!)
Gap:            0.05 (bÃ¼yÃ¼yor!)
```

**Analoji - SÄ±nav:**
```
Ã–ÄŸrenci: SorularÄ± ezberledi
Ders Ã§alÄ±ÅŸÄ±rken: %100 doÄŸru (ezber!)
SÄ±navda: %65 doÄŸru (farklÄ± sorularda kÃ¶tÃ¼!)

EÄŸitim mÃ¼kemmel, test kÃ¶tÃ¼ â†’ Overfitting!
```

**GÃ¶rsel:**
```
CO â†‘
   |    Ã—
   | /\/\Ã—/\    â† Noktalar
   |Ã—/\/ Ã—/\Ã—
   |\/Ã—  \/  Ã—  â† AÅŸÄ±rÄ± karmaÅŸÄ±k eÄŸri
   |/_____________â†’ T

Model her noktayÄ± geÃ§iyor!
Ama gÃ¼rÃ¼ltÃ¼yÃ¼ de Ã¶ÄŸrendi, genelleyemiyor!
```

---

## ğŸ“Š Lab 5'in Ana GrafiÄŸi: U-Shaped Curve

### Validation Curve

```
Hata â†‘
    |
    |  Test HatasÄ± (KÄ±rmÄ±zÄ±)
    |    \___________/
    |
    |     \___________  EÄŸitim HatasÄ± (YeÅŸil)
    |
    +_____________________â†’ KarmaÅŸÄ±klÄ±k (Degree)
      1  2  3  4  5  6  7  8  9  10

    Underfitting  Optimal  Overfitting
```

### Ne GÃ¶rÃ¼yoruz?

**EÄŸitim HatasÄ± (YeÅŸil):**
- SÃ¼rekli azalÄ±yor â†“
- Degree arttÄ±kÃ§a model eÄŸitim verisine daha iyi uyuyor
- âŒ **YanÄ±ltÄ±cÄ±!** Bu iyi model anlamÄ±na gelmez!

**Test HatasÄ± (KÄ±rmÄ±zÄ±):**
- U-ÅŸekli yapÄ±yor!
- Ã–nce azalÄ±yor â†“ (iyileÅŸiyor)
- Sonra artÄ±yor â†‘ (overfitting baÅŸlÄ±yor)
- âœ… **DoÄŸru metric!** Buna bakmamÄ±z gerekiyor!

**Optimal Nokta:**
- Test hatasÄ±nÄ±n **en dÃ¼ÅŸÃ¼k** olduÄŸu yer
- Lab 5'te: **Degree 9**

---

## ğŸ§  Bias ve Variance Nedir?

### Bias (Ã–nyargÄ±/YanlÄ±lÄ±k)

**TanÄ±m:** Modelin **sistematik hatalarÄ±**

**YÃ¼ksek Bias:**
- Model Ã§ok basit
- GerÃ§ek iliÅŸkiyi yakalayamÄ±yor
- **Underfitting**

**DÃ¼ÅŸÃ¼k Bias:**
- Model yeterince karmaÅŸÄ±k
- Ä°liÅŸkileri yakalayabiliyor

**Ã–rnek:**
```
GerÃ§ek iliÅŸki: CO eÄŸrisel olarak artÄ±yor
Model (degree 1): DÃ¼z Ã§izgi
SonuÃ§: Her zaman biraz yanÄ±lÄ±yor â†’ YÃ¼ksek bias
```

### Variance (Varyans/DeÄŸiÅŸkenlik)

**TanÄ±m:** Modelin **farklÄ± verilerle ne kadar deÄŸiÅŸtiÄŸi**

**YÃ¼ksek Variance:**
- Model Ã§ok karmaÅŸÄ±k
- EÄŸitim verisine Ã§ok baÄŸÄ±mlÄ±
- FarklÄ± veride Ã§ok deÄŸiÅŸiyor
- **Overfitting**

**DÃ¼ÅŸÃ¼k Variance:**
- Model kararlÄ±
- FarklÄ± verilerde tutarlÄ±

**Ã–rnek:**
```
Degree 10 model:
EÄŸitim seti 1: CO = ...Ã§ok karmaÅŸÄ±k formÃ¼l 1...
EÄŸitim seti 2: CO = ...tamamen farklÄ± formÃ¼l 2...
SonuÃ§: Ã‡ok deÄŸiÅŸken â†’ YÃ¼ksek variance
```

---

## âš–ï¸ Tradeoff (Ã–dÃ¼nleÅŸim) Nedir?

### Temel Ä°lke

**Bias â†“ (azalttÄ±kÃ§a) â†’ Variance â†‘ (artÄ±yor)**
**Variance â†“ (azalttÄ±kÃ§a) â†’ Bias â†‘ (artÄ±yor)**

Ä°kisini de aynÄ± anda azaltamazsÄ±nÄ±z!

### Matematiksel

```
Toplam Hata = BiasÂ² + Variance + GÃ¼rÃ¼ltÃ¼

AmaÃ§: BiasÂ² + Variance'Ä± minimize et!
```

### GÃ¶rsel

```
           â†‘ Bias & Variance
           |
YÃ¼ksek     |     Bias
           |      \
           |       \___
Bias/Var   |           \___      Optimal!
           |               \___Ã—
           |                   \
           |        Variance    \___
DÃ¼ÅŸÃ¼k      |_________________________â†’
             Basit            KarmaÅŸÄ±k
                Model Kompleksitesi
```

---

## ğŸ¯ Lab 5'te Bias-Variance

### Degree 1 (Linear)

```
Bias:     YÃ¼ksek â†‘
Variance: DÃ¼ÅŸÃ¼k â†“
SonuÃ§:    Underfitting

Neden?
- Ã‡ok basit formÃ¼l
- GerÃ§ek iliÅŸkiyi yakalayamÄ±yor (bias)
- Ama kararlÄ±, tutarlÄ± (dÃ¼ÅŸÃ¼k variance)
```

### Degree 9 (Optimal)

```
Bias:     Orta â†’
Variance: Orta â†’
SonuÃ§:    Dengeli!

Neden?
- Yeterince karmaÅŸÄ±k (bias dÃ¼ÅŸÃ¼k)
- Ama Ã§ok da karmaÅŸÄ±k deÄŸil (variance kontrol altÄ±nda)
- **En iyi genelleme!**
```

### Degree 10 (Overfit)

```
Bias:     DÃ¼ÅŸÃ¼k â†“
Variance: YÃ¼ksek â†‘
SonuÃ§:    Overfitting

Neden?
- Ã‡ok karmaÅŸÄ±k formÃ¼l
- EÄŸitim verisine mÃ¼kemmel uyuyor (bias dÃ¼ÅŸÃ¼k)
- Ama gÃ¼rÃ¼ltÃ¼yÃ¼ de Ã¶ÄŸrendi (yÃ¼ksek variance)
```

---

## ğŸ“ˆ Pratik NasÄ±l AnlarsÄ±nÄ±z?

### Test 1: EÄŸitim vs Test HatasÄ±

```
Her ikisi de yÃ¼ksek:
  â†’ Underfitting (degree Ã§ok dÃ¼ÅŸÃ¼k)

Test < EÄŸitim (yakÄ±n):
  â†’ Ä°yi fit (optimal degree)

Test >> EÄŸitim (bÃ¼yÃ¼k fark):
  â†’ Overfitting (degree Ã§ok yÃ¼ksek)
```

### Test 2: Error Gap

```python
gap = test_error - train_error

gap kÃ¼Ã§Ã¼k (< 0.05):  Good!
gap orta (0.05-0.10): Dikkat
gap bÃ¼yÃ¼k (> 0.10):   Overfitting!
```

### Test 3: Cross-Validation

```
CV standard deviation yÃ¼ksek:
  â†’ Model tutarsÄ±z (overfitting riski)

CV standard deviation dÃ¼ÅŸÃ¼k:
  â†’ Model kararlÄ± (gÃ¼venilir)
```

---

## ğŸ’¡ GerÃ§ek Hayat Ã–rnekleri

### Ã–rnek 1: Hava Durumu Tahmini

**Underfitting:**
```
Model: "Her gÃ¼n 20Â°C olacak"
SonuÃ§: HiÃ§bir zaman doÄŸru deÄŸil
```

**Good Fit:**
```
Model: "Mevsimi, bÃ¶lgeyi, tarihi dikkate al"
SonuÃ§: Genelde doÄŸru tahminler
```

**Overfitting:**
```
Model: "GeÃ§en yÄ±l bugÃ¼n 23.4Â°C'ydi, bu yÄ±l da Ã¶yle olacak"
SonuÃ§: Ã‡ok spesifik, genelleyemiyor
```

### Ã–rnek 2: SÄ±nav Stratejisi

**Underfitting (HiÃ§ Ã§alÄ±ÅŸmama):**
- Konuyu anlamÄ±yorsunuz
- Her sÄ±navda kÃ¶tÃ¼

**Good Fit (Ä°yi Ã§alÄ±ÅŸma):**
- Konuyu anlÄ±yorsunuz
- FarklÄ± sorulara adapte olabiliyorsunuz

**Overfitting (Sadece ezber):**
- Ã‡Ã¶zdÃ¼ÄŸÃ¼nÃ¼z sorularÄ± mÃ¼kemmel biliyorsunuz
- Ama yeni soru tiplerinde baÅŸarÄ±sÄ±z oluyorsunuz

---

## ğŸ”§ NasÄ±l DÃ¼zeltiriz?

### Underfitting'i Ã‡Ã¶zmek

1. **Model kompleksitesini artÄ±r**
   ```python
   degree = 1 â†’ degree = 3
   ```

2. **Daha fazla Ã¶zellik ekle**
   ```python
   Sadece T â†’ T, RH, AH, RÃ¼zgar, Saat...
   ```

3. **Daha karmaÅŸÄ±k model kullan**
   ```python
   Linear â†’ Polynomial
   ```

### Overfitting'i Ã‡Ã¶zmek

1. **Model kompleksitesini azalt**
   ```python
   degree = 10 â†’ degree = 5
   ```

2. **Daha fazla veri topla**
   ```
   5,000 Ã¶rnek â†’ 50,000 Ã¶rnek
   ```

3. **Regularization kullan**
   ```python
   Ridge, Lasso regression
   ```

4. **Cross-validation yap**
   ```python
   Tek split yerine 5-fold CV
   ```

---

## ğŸ“ Lab 5'in SonuÃ§larÄ±

### BulgularÄ±mÄ±z

| Degree | Train MSE | Test MSE | Gap | Durum |
|--------|-----------|----------|-----|-------|
| 1      | 2.04      | 2.06     | 0.01 | Underfitting |
| 5      | 1.98      | 2.01     | 0.03 | Ä°yi |
| **9**  | **1.95**  | **1.98** | **0.03** | **Optimal!** |
| 10     | 1.94      | 1.99     | 0.05 | BaÅŸlangÄ±Ã§ overfitting |

### SonuÃ§

- **Degree 9**: En iyi genelleme
- **Neden?** Bias ve variance dengesi!
- **Cross-validation:** Degree 1 daha stabil (ama daha yÃ¼ksek hata)

---

## ğŸ’­ Ã–nemli Kavramlar

### 1. Training Error AldatÄ±cÄ±dÄ±r!

```
âŒ "EÄŸitim hatam 0.001, sÃ¼per model!"
âœ… "Test hatam 0.05, iyi model!"
```

### 2. Test Error GerÃ§eÄŸi GÃ¶sterir!

```
Test hatasÄ± = GerÃ§ek performans
```

### 3. Gap Overfitting GÃ¶stergesi!

```
BÃ¼yÃ¼k gap = Ezber yapÄ±yor = Overfitting!
```

### 4. Optimal â‰  EÄŸitim HatasÄ± En DÃ¼ÅŸÃ¼k!

```
Optimal = Test HatasÄ± En DÃ¼ÅŸÃ¼k!
```

---

## ğŸš€ Ã–zet

### Bias-Variance Tradeoff 3 CÃ¼mlede

1. **Ã‡ok basit model:** YÃ¼ksek bias â†’ Underfitting
2. **Ã‡ok karmaÅŸÄ±k model:** YÃ¼ksek variance â†’ Overfitting
3. **Optimal model:** Bias ve variance dengesi â†’ Best generalization!

### Lab 5'in MesajÄ±

**"Daha karmaÅŸÄ±k her zaman daha iyi deÄŸildir!"**

En iyi model, **test verisinde en iyi performans gÃ¶sterendir**!

---

**HazÄ±rlayan:** Muhammed Ali KarataÅŸ (2021403030)
**Tarih:** 12 KasÄ±m 2025
