# SÄ±k Sorulan Sorular - Lab 5

**Ã–ÄŸrenci:** Muhammed Ali KarataÅŸ (2021403030)
**Tarih:** 12 KasÄ±m 2025

---

## ğŸ¤” TEMEL SORULAR

### S1: Sklearn tam olarak nedir?

**C:** Sklearn (Scikit-learn), Python'da machine learning yapmak iÃ§in kullanÄ±lan bir kÃ¼tÃ¼phanedir. HazÄ±r algoritmalar, veri iÅŸleme araÃ§larÄ± ve model deÄŸerlendirme fonksiyonlarÄ± sunar.

**Benzetme:** Excel gibi! Excel'de hazÄ±r formÃ¼ller var (SUM, AVERAGE). Sklearn'de de hazÄ±r ML algoritmalarÄ± var (LinearRegression, PolynomialFeatures).

---

### S2: Model nasÄ±l "Ã¶ÄŸreniyor"?

**C:** Model, **en iyi parametreleri (Î² katsayÄ±larÄ±nÄ±) bulmaya** Ã§alÄ±ÅŸÄ±yor.

**AdÄ±mlar:**
1. Random Î² deÄŸerleriyle baÅŸla
2. Tahminler yap
3. HatalarÄ± hesapla
4. Î²'larÄ± deÄŸiÅŸtir, hatayÄ± azalt
5. En dÃ¼ÅŸÃ¼k hata bulunana kadar tekrarla!

Bu sÃ¼reÃ§ `model.fit()` iÃ§inde otomatik oluyor!

---

### S3: Training ve testing neden ayrÄ±?

**C:** **Ezberle vs. Ã–ÄŸrenme** ayrÄ±mÄ± iÃ§in!

**Analoji:**
- Training = Ders Ã§alÄ±ÅŸma
- Testing = GerÃ§ek sÄ±nav (hiÃ§ gÃ¶rmedin!)

EÄŸer tÃ¼m veriyi eÄŸitimde kullansak, model ezberlemiÅŸ olabilir. Test verisi, **yeni verilerde ne kadar iyi olduÄŸunu** gÃ¶sterir.

---

### S4: Polynomial nedir? Neden kullanÄ±yoruz?

**C:** Polynomial, **eÄŸrisel iliÅŸkileri** yakalamamÄ±zÄ± saÄŸlÄ±yor.

**Linear (degree 1):**
```
CO = Î²â‚€ + Î²â‚Ã—T
```
Sadece dÃ¼z Ã§izgi!

**Polynomial (degree 2):**
```
CO = Î²â‚€ + Î²â‚Ã—T + Î²â‚‚Ã—TÂ²
```
EÄŸri Ã§izebiliyor!

**Neden?** GerÃ§ek hayatta iliÅŸkiler genelde dÃ¼z deÄŸil, eÄŸrisel!

---

## ğŸ“Š KAVRAMSAL SORULAR

### S5: Bias nedir?

**C:** Model'in **sistematik hatalarÄ±**.

**Ã–rnek:**
- GerÃ§ek iliÅŸki eÄŸrisel
- Model dÃ¼z Ã§izgi Ã§iziyor
- SonuÃ§: Her zaman biraz yanÄ±lÄ±yor â†’ YÃ¼ksek bias!

**DÃ¼ÅŸÃ¼k bias:** Model gerÃ§ek iliÅŸkiye yakÄ±n
**YÃ¼ksek bias:** Model Ã§ok basit, iliÅŸkiyi yakalayamÄ±yor

---

### S6: Variance nedir?

**C:** Model'in **farklÄ± verilerle ne kadar deÄŸiÅŸtiÄŸi**.

**Ã–rnek:**
- EÄŸitim seti 1: Model A Ã¶ÄŸreniyor
- EÄŸitim seti 2: Tamamen farklÄ± Model B Ã¶ÄŸreniyor
- SonuÃ§: Ã‡ok deÄŸiÅŸken â†’ YÃ¼ksek variance!

**DÃ¼ÅŸÃ¼k variance:** Model tutarlÄ±
**YÃ¼ksek variance:** Model Ã§ok hassas, her veriye farklÄ± uyuyor

---

### S7: Underfitting nedir?

**C:** Model **Ã§ok basit**, Ã¶nemli iliÅŸkileri yakalayamÄ±yor.

**Belirtiler:**
- Hem eÄŸitim hem test hatasÄ± **yÃ¼ksek**
- Model deseni gÃ¶rmÃ¼yor
- Degree Ã§ok dÃ¼ÅŸÃ¼k

**Ã‡Ã¶zÃ¼m:** Model kompleksitesini artÄ±r!

---

### S8: Overfitting nedir?

**C:** Model **Ã§ok karmaÅŸÄ±k**, eÄŸitim verisini ezberliyor.

**Belirtiler:**
- EÄŸitim hatasÄ± Ã§ok **dÃ¼ÅŸÃ¼k**
- Test hatasÄ± **yÃ¼ksek**
- **BÃ¼yÃ¼k gap** var!
- Degree Ã§ok yÃ¼ksek

**Ã‡Ã¶zÃ¼m:** Model kompleksitesini azalt veya daha fazla veri topla!

---

### S9: Bias-variance tradeoff nedir?

**C:** Bias ve variance arasÄ±nda **Ã¶dÃ¼nleÅŸim** var!

```
Bias â†“ (azalÄ±r) â†’ Variance â†‘ (artar)
Variance â†“ (azalÄ±r) â†’ Bias â†‘ (artar)
```

Ä°kisini de aynÄ± anda azaltamazsÄ±nÄ±z! **Optimal nokta**, ikisinin de dengeli olduÄŸu yerdir.

---

## ğŸ’» KOD SORULARI

### S10: `model.fit()` ne yapÄ±yor?

**C:** Model'i **eÄŸitiyor** (training).

```python
model.fit(X_train, y_train)
```

**Ne oluyor:**
1. X_train'deki Ã¶zelliklere bakÄ±yor
2. y_train'deki Ã§Ä±ktÄ±lara bakÄ±yor
3. En iyi Î² katsayÄ±larÄ±nÄ± buluyor
4. FormÃ¼lÃ¼ Ã¶ÄŸreniyor: `CO = Î²â‚€ + Î²â‚Ã—T + ...`

**SonuÃ§:** Model artÄ±k tahmin yapabilir!

---

### S11: `model.predict()` ne yapÄ±yor?

**C:** Model Ã¶ÄŸrendiÄŸi formÃ¼lle **tahmin yapÄ±yor**.

```python
predictions = model.predict(X_test)
```

**Ne oluyor:**
1. X_test'teki her satÄ±r iÃ§in
2. Ã–ÄŸrendiÄŸi formÃ¼lÃ¼ uygula
3. CO deÄŸerini hesapla
4. Tahminleri dÃ¶ndÃ¼r

**Ã–rnek:**
```
Input: T=20, RH=50, AH=1.0
Model: CO = 0.5 + 0.03Ã—20 + 0.01Ã—50 + 0.8Ã—1.0
Output: CO = 2.4 mg/mÂ³
```

---

### S12: `PolynomialFeatures()` ne yapÄ±yor?

**C:** Ã–zellikleri **polynomial terimlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor**.

**Degree 1:**
```python
Input:  [T, RH, AH]
Output: [T, RH, AH]
# DeÄŸiÅŸiklik yok
```

**Degree 2:**
```python
Input:  [T, RH, AH]
Output: [T, RH, AH, TÂ², TÃ—RH, TÃ—AH, RHÂ², RHÃ—AH, AHÂ²]
# 3 terim â†’ 9 terim!
```

**Neden?** Linear regression'a eÄŸrileri Ã¶ÄŸretmek iÃ§in!

---

### S13: `mean_squared_error()` ne yapÄ±yor?

**C:** Tahminlerin **ne kadar yanlÄ±ÅŸ olduÄŸunu** Ã¶lÃ§Ã¼yor.

**FormÃ¼l:**
```
MSE = (hataâ‚Â² + hataâ‚‚Â² + ... + hataâ‚™Â²) / n

hata = gerÃ§ek - tahmin
```

**Ã–rnek:**
```
GerÃ§ek: [2.0, 3.0, 2.5]
Tahmin: [2.1, 2.8, 2.6]
Hata:   [0.1, -0.2, 0.1]
MSE = (0.01 + 0.04 + 0.01) / 3 = 0.02
```

**DÃ¼ÅŸÃ¼k MSE = Ä°yi model!**

---

## ğŸ“ˆ GRAFÄ°K SORULARI

### S14: Validation curve nasÄ±l okunur?

**C:** Ä°ki Ã§izgiye bakÄ±n:

**YeÅŸil (Training Error):**
- SÃ¼rekli azalÄ±yor
- âŒ Buna bakmayÄ±n! YanÄ±ltÄ±cÄ±!

**KÄ±rmÄ±zÄ± (Test Error):**
- U-ÅŸekli yapÄ±yor
- âœ… Buna bakÄ±n! Bu gerÃ§ek performans!
- **En dÃ¼ÅŸÃ¼k nokta = Optimal model!**

---

### S15: U-ÅŸekli neden oluÅŸuyor?

**C:** Bias-variance tradeoff!

```
Sol taraf (Degree 1-2):
  YÃ¼ksek bias â†’ Hata yÃ¼ksek â†’ Underfitting

Orta (Degree 5-9):
  Dengeli â†’ Hata dÃ¼ÅŸÃ¼k â†’ Optimal!

SaÄŸ taraf (Degree 10):
  YÃ¼ksek variance â†’ Hata artÄ±yor â†’ Overfitting
```

---

### S16: Gap nedir?

**C:** Test hatasÄ± ile eÄŸitim hatasÄ± arasÄ±ndaki fark.

```python
gap = test_error - train_error
```

**KÃ¼Ã§Ã¼k gap (< 0.05):** Good!
**Orta gap (0.05-0.10):** Dikkat!
**BÃ¼yÃ¼k gap (> 0.10):** Overfitting!

---

## ğŸ¯ LAB 5 SPESÄ°FÄ°K SORULAR

### S17: Neden 3 Ã¶zellik kullanÄ±yoruz?

**C:** Lab'Ä±n amacÄ±na uygun!

**KullandÄ±ÄŸÄ±mÄ±z:**
- T (SÄ±caklÄ±k)
- RH (BaÄŸÄ±l nem)
- AH (Mutlak nem)

**Neden sadece bunlar?**
- Lab, **bias-variance** Ã¶ÄŸretmeye odaklanÄ±yor
- Ã‡ok Ã¶zellik olsa, Ã§ok karmaÅŸÄ±k olurdu
- Basit tutmak pedagojik amaÃ§lÄ±!

**GerÃ§ek hayatta:** Daha Ã§ok Ã¶zellik kullanÄ±lÄ±r (rÃ¼zgar, trafik, saat, vs.)

---

### S18: RÂ² neden Ã§ok dÃ¼ÅŸÃ¼k (%4)?

**C:** Ã‡Ã¼nkÃ¼ **sadece 3 meteorolojik Ã¶zellik** kullanÄ±yoruz!

**RÂ² = 0.04 demek:**
- Model, CO varyansÄ±nÄ±n sadece %4'Ã¼nÃ¼ aÃ§Ä±klayabiliyor
- %96 baÅŸka faktÃ¶rlerden kaynaklanÄ±yor

**Hangi faktÃ¶rler eksik?**
- Trafik yoÄŸunluÄŸu (en Ã¶nemli!)
- RÃ¼zgar hÄ±zÄ± ve yÃ¶nÃ¼
- Saat (sabah trafiÄŸi)
- Mevsim
- Emisyon kaynaklarÄ±

**Lab'Ä±n amacÄ±:** YÃ¼ksek RÂ² deÄŸil, bias-variance'Ä± anlamak!

---

### S19: Neden degree 9 optimal, 10 deÄŸil?

**C:** Degree 10'da **overfitting baÅŸlÄ±yor**.

**KanÄ±t:**
```
Degree 9:
  Train: 1.95
  Test:  1.98
  Gap:   0.03

Degree 10:
  Train: 1.94 (daha dÃ¼ÅŸÃ¼k!)
  Test:  1.99 (arttÄ±!)
  Gap:   0.05 (bÃ¼yÃ¼dÃ¼!)
```

Degree 10, eÄŸitim verisine daha iyi uyuyor ama test'te kÃ¶tÃ¼leÅŸiyor â†’ Overfitting!

---

### S20: Cross-validation neden degree 1 Ã¶neriyor?

**C:** Ã‡Ã¼nkÃ¼ CV **daha gÃ¼venilir ve stabil** modeli seÃ§iyor!

**Single split:**
- Tek bir rastgele ayÄ±rma
- ÅanslÄ±/ÅŸanssÄ±z olabilir
- Degree 9 en dÃ¼ÅŸÃ¼k test hatasÄ±

**Cross-validation:**
- 5 farklÄ± ayÄ±rmayÄ± test ediyor
- Daha gÃ¼venilir
- Degree 1 en **tutarlÄ±** (standart sapma dÃ¼ÅŸÃ¼k)

**Hangisi doÄŸru?**
- Degree 9: En dÃ¼ÅŸÃ¼k hata, ama varyans yÃ¼ksek
- Degree 1: Biraz daha yÃ¼ksek hata, ama Ã§ok tutarlÄ±

**GerÃ§ek projede:** Degree 1 daha gÃ¼venli seÃ§im olurdu!

---

## ğŸ› PROBLEM Ã‡Ã–ZME

### S21: "ModuleNotFoundError: No module named 'sklearn'"

**C:** Python versiyonu yanlÄ±ÅŸ veya sklearn kurulu deÄŸil!

**Ã‡Ã¶zÃ¼m 1:** DoÄŸru Python kullan
```bash
/Users/alikaratas/miniconda3/bin/python3 code/run_lab5.py
```

**Ã‡Ã¶zÃ¼m 2:** Conda aktive et
```bash
conda activate base
python3 code/run_lab5.py
```

**Ã‡Ã¶zÃ¼m 3:** Sklearn kur
```bash
pip install scikit-learn
```

---

### S22: "FileNotFoundError: AirQualityUCI.csv"

**C:** CSV dosyasÄ± doÄŸru yerde deÄŸil veya yanlÄ±ÅŸ dizindesiniz!

**Ã‡Ã¶zÃ¼m:** DoÄŸru dizine gidin
```bash
cd /Users/alikaratas/Downloads/lab5
python3 code/run_lab5.py
```

Veya script'i gÃ¼ncelleyin:
```python
df = pd.read_csv('dataset/AirQualityUCI.csv', ...)
```

---

### S23: Jupyter notebook Ã§alÄ±ÅŸmÄ±yor!

**C:** Jupyter kurulu deÄŸil veya Python versiyonu yanlÄ±ÅŸ!

**Ã‡Ã¶zÃ¼m:**
```bash
# Jupyter kur
pip install jupyter

# Notebook aÃ§
jupyter notebook Lab5_BiasVariance.ipynb

# Sonra: Kernel â†’ Restart & Run All
```

---

## ğŸ’¡ Ä°LERÄ° SEVIYE SORULAR

### S24: Gradient Descent nedir?

**C:** Modelin parametreleri (Î²) **optimize etme yÃ¶ntemi**.

**Benzetme:** KaranlÄ±kta daÄŸdan inme
1. Rastgele bir yerden baÅŸla
2. Hangi yÃ¶n aÅŸaÄŸÄ±? (Gradient hesapla)
3. O yÃ¶ne kÃ¼Ã§Ã¼k adÄ±m at
4. Tekrarla â†’ En alÃ§ak noktayÄ± bul!

**Lab 5'te:** Sklearn otomatik yapÄ±yor (Normal Equation kullanÄ±yor).

---

### S25: Regularization nedir?

**C:** Overfitting'i Ã¶nlemek iÃ§in **model kompleksitesine ceza** verme!

**Ridge Regression:**
```
Minimize et: MSE + Î»Ã—(Î²â‚Â² + Î²â‚‚Â² + ... + Î²â‚™Â²)
```

Î» bÃ¼yÃ¼k â†’ KatsayÄ±lar kÃ¼Ã§Ã¼k â†’ Basit model â†’ Az overfitting

**Lab 5'te:** KullanmÄ±yoruz, ama bonus olarak eklenebilir!

---

### S26: Feature scaling gerekli mi?

**C:** BazÄ± algoritmalarda evet, Linear Regression'da **gerekli deÄŸil**!

**Gerekli olan algoritmalar:**
- K-Nearest Neighbors
- Support Vector Machines
- Neural Networks

**Gerekli olmayan:**
- Linear Regression
- Decision Trees

**Lab 5'te:** YapmÄ±yoruz Ã§Ã¼nkÃ¼ gerekli deÄŸil!

---

## ğŸ“š KAVRAM KARÅILAÅTIRMA

### S27: MSE vs RMSE vs RÂ² - Hangisi daha iyi?

**C:** Hepsi farklÄ± bilgi verir!

**MSE (Mean Squared Error):**
- Matematiksel olarak iÅŸlem yapmaya uygun
- Birim: (mg/mÂ³)Â²
- YorumlamasÄ± zor

**RMSE (Root MSE):**
- MSE'nin karekÃ¶kÃ¼
- Birim: mg/mÂ³ (hedefle aynÄ±!)
- YorumlamasÄ± kolay: "Ortalama hata 1.4 mg/mÂ³"

**RÂ² (Coefficient of Determination):**
- AÃ§Ä±klanan varyans yÃ¼zdesi
- 0-1 arasÄ± (1 = mÃ¼kemmel)
- Model'in genel baÅŸarÄ±sÄ±nÄ± gÃ¶sterir

**Hangisini kullanmalÄ±:**
- Optimizasyon iÃ§in: MSE
- Yorumlama iÃ§in: RMSE
- Genel baÅŸarÄ± iÃ§in: RÂ²

---

### S28: Training error vs Validation error vs Test error?

**C:** FarklÄ± aÅŸamalarda kullanÄ±lÄ±yor!

**Training Error:**
- Model'in eÄŸitim verisindeki hatasÄ±
- Her zaman yanÄ±ltÄ±cÄ±!
- DÃ¼ÅŸÃ¼k olmasÄ± iyi model anlamÄ±na gelmez

**Validation Error:**
- Model seÃ§imi iÃ§in kullanÄ±lan hata
- Cross-validation'da hesaplanÄ±r
- En iyi hiperparametreyi bulmak iÃ§in

**Test Error:**
- Final performans Ã¶lÃ§Ã¼mÃ¼
- En son, tek sefer hesaplanÄ±r
- GerÃ§ek performansÄ± gÃ¶sterir

**Lab 5'te:**
- Training error hesaplÄ±yoruz (karÅŸÄ±laÅŸtÄ±rma iÃ§in)
- Test error kullanÄ±yoruz (model seÃ§imi iÃ§in)
- Validation: Cross-validation bonus'ta var

---

## ğŸ“ SINAV/SUNUM SORULARI

### S29: Bias-variance tradeoff'u nasÄ±l aÃ§Ä±klarÄ±m?

**C:** 3 adÄ±mda:

**1. Sorun:**
"Model ne kadar karmaÅŸÄ±k olmalÄ±?"

**2. Ä°ki uÃ§:**
- Ã‡ok basit â†’ YÃ¼ksek bias â†’ Underfitting
- Ã‡ok karmaÅŸÄ±k â†’ YÃ¼ksek variance â†’ Overfitting

**3. Ã‡Ã¶zÃ¼m:**
"Optimal model, test hatasÄ±nÄ±n en dÃ¼ÅŸÃ¼k olduÄŸu dengede!"

**Grafik gÃ¶ster:** U-shaped curve!

---

### S30: Lab 5'in ana mesajÄ± nedir?

**C:**

> **"Daha karmaÅŸÄ±k her zaman daha iyi deÄŸildir!
> En iyi model, yeni verilerde en iyi performans gÃ¶sterendir!"**

**KanÄ±t:** Lab 5'te:
- Degree 10: En dÃ¼ÅŸÃ¼k eÄŸitim hatasÄ±
- Degree 9: En dÃ¼ÅŸÃ¼k test hatasÄ± â†’ Bu daha Ã¶nemli!

---

## ğŸš€ SON TAVSÄ°YELER

### SÄ±nav Ä°Ã§in
1. Bias-variance kavramlarÄ±nÄ± **Ã¶rneklerle** aÃ§Ä±klayabilin
2. U-shaped curve'Ã¼ **Ã§izebilir ve yorumlayabilin**
3. Training vs test error **farkÄ±nÄ±** anlayÄ±n
4. Overfitting'in **nasÄ±l tespit edileceÄŸini** bilin

### Proje Ä°Ã§in
1. Kodu **satÄ±r satÄ±r** anlayÄ±n
2. Grafikleri **yorumlayabilin**
3. SonuÃ§larÄ± **aÃ§Ä±klayabilin**
4. Alternatif Ã§Ã¶zÃ¼mler **Ã¶nerebilir**

### Kariyer Ä°Ã§in
1. Bu konseptler **her ML projesinde** kullanÄ±lÄ±r!
2. Interview'larda **sÄ±kÃ§a sorulur**
3. GerÃ§ek problemlerde **kritik Ã¶nem** taÅŸÄ±r!

---

**HazÄ±rlayan:** Muhammed Ali KarataÅŸ (2021403030)
**Tarih:** 12 KasÄ±m 2025
**Durum:** âœ… 30 Soru CevaplandÄ±!
