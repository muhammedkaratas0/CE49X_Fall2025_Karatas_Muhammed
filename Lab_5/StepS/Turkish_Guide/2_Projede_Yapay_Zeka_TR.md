# Lab 5'te Yapay Zeka NasÄ±l KullanÄ±lÄ±yor?

**Ã–ÄŸrenci:** Muhammed Ali KarataÅŸ (2021403030)
**Tarih:** 12 KasÄ±m 2025

---

## ğŸ¯ Bu DokÃ¼manda Ne Ã–ÄŸreneceksiniz?

1. Lab 5'te **tam olarak ne yapÄ±yoruz**?
2. **Yapay zeka** kodun neresinde?
3. Model **nasÄ±l Ã¶ÄŸreniyor**?
4. **Training ve Testing** neden ayrÄ±?
5. AdÄ±m adÄ±m **ne oluyor**?

---

## ğŸŒ Projenin Genel Resmi

### Problem TanÄ±mÄ±

**Soru:** Ä°talya'daki bir hava kalitesi istasyonundan **CO (Karbon Monoksit) konsantrasyonunu** tahmin edebilir miyiz?

**Elimizde ne var?**
- ğŸ“Š 9,471 saatlik Ã¶lÃ§Ã¼m verisi
- ğŸŒ¡ï¸ SÄ±caklÄ±k (T)
- ğŸ’§ BaÄŸÄ±l Nem (RH - Relative Humidity)
- ğŸ’¦ Mutlak Nem (AH - Absolute Humidity)
- ğŸ­ CO konsantrasyonu (tahmin etmek istediÄŸimiz)

**Ne istiyoruz?**
Yeni bir Ã¶lÃ§Ã¼mde (Ã¶rneÄŸin: T=23Â°C, RH=55%, AH=1.1 g/mÂ³), CO'nun ne olacaÄŸÄ±nÄ± **tahmin etmek**!

---

## ğŸ¤– Yapay Zeka Nerede KullanÄ±lÄ±yor?

### Kodun AI KÄ±smÄ±

```python
# 1. MODEL OLUÅTURMA (AI burada baÅŸlÄ±yor!)
from sklearn.linear_model import LinearRegression
model = LinearRegression()  # â† Yapay zeka modeli!

# 2. MODEL EÄÄ°TÄ°MÄ° (AI Ã¶ÄŸreniyor!)
model.fit(X_train, y_train)  # â† BurasÄ± sihir!

# 3. TAHMÄ°N (AI bilgisini kullanÄ±yor!)
predictions = model.predict(X_test)  # â† AI tahmin yapÄ±yor!
```

**AÃ§Ä±klama:**
- `LinearRegression()`: Yapay zeka **algoritmasÄ±** (beyin)
- `fit()`: Model **Ã¶ÄŸreniyor** (eÄŸitim)
- `predict()`: Model **tahmin yapÄ±yor** (kullanÄ±m)

---

## ğŸ“š Lab 5'in Hikayesi (AdÄ±m AdÄ±m)

### Senaryo: Hava Kalitesi Tahmini

Hayal edin: Ä°talya'da bir Ã§evre mÃ¼hendisi Ã§alÄ±ÅŸÄ±yorsunuz.

#### **BÃ¶lÃ¼m 1: Veri Toplama** ğŸ“Š

```python
# Ä°talyan istasyonundan veri geldi!
df = pd.read_csv('AirQualityUCI.csv')
# 9,471 saatlik Ã¶lÃ§Ã¼m!
```

**Veri nasÄ±l gÃ¶rÃ¼nÃ¼yor?**
```
Tarih        Saat      T     RH    AH    CO(GT)
10/03/2004  18:00:00  13.6  48.9  0.76   2.6
10/03/2004  19:00:00  13.3  47.7  0.73   2.0
10/03/2004  20:00:00  11.9  54.0  0.75   2.2
...
```

Her satÄ±r = 1 saatlik Ã¶lÃ§Ã¼m
- T = SÄ±caklÄ±k (Â°C)
- RH = BaÄŸÄ±l nem (%)
- AH = Mutlak nem (g/mÂ³)
- CO(GT) = GerÃ§ek CO deÄŸeri (mg/mÂ³)

#### **BÃ¶lÃ¼m 2: Veri Temizleme** ğŸ§¹

```python
# Sorunlu deÄŸerleri temizle
df_clean = df.replace(-200.0, np.nan)  # -200 = kayÄ±p veri
data_cleaned = data.dropna()  # KayÄ±p olanlarÄ± Ã§Ä±kar
```

**SonuÃ§:** 7,344 temiz veri satÄ±rÄ± kaldÄ±!

**Neden temizleme?**
- SensÃ¶r bazen arÄ±zalanÄ±yor (-200 gÃ¶nderiyor)
- AI, bozuk veriyle Ã¶ÄŸrenemez!

#### **BÃ¶lÃ¼m 3: Veriyi AyÄ±rma** âœ‚ï¸

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
```

**Ne oluyor?**
```
Toplam: 7,344 veri
    â†“
    â”œâ”€ EÄŸitim (70%): 5,140 veri  â† Model bunlarla Ã¶ÄŸrenecek
    â””â”€ Test (30%):   2,204 veri  â† Model bunlarÄ± GÃ–RMEYECEK!
```

**Analoji - SÄ±nav HazÄ±rlÄ±ÄŸÄ±:**

**EÄŸitim Verisi = Ders Ã‡alÄ±ÅŸma**
```
Ã–ÄŸrenci: "Åu Ã¶rnekleri Ã§Ã¶z, Ã¶ÄŸren"
         (5,140 Ã¶rnek soru)
```

**Test Verisi = GerÃ§ek SÄ±nav**
```
Ã–ÄŸretmen: "HiÃ§ gÃ¶rmediÄŸin sorularÄ± Ã§Ã¶z!"
          (2,204 yeni soru)
```

**Neden ayÄ±rÄ±yoruz?**
- Ezberle

me vs Ã–ÄŸrenme ayrÄ±mÄ±!
- Modelin **yeni verilerde** ne kadar iyi olduÄŸunu gÃ¶rmek iÃ§in!

#### **BÃ¶lÃ¼m 4: Model EÄŸitimi** ğŸ“

##### Degree 1 (Linear - En Basit)

```python
# Degree 1: DÃ¼z Ã§izgi iliÅŸkisi
poly = PolynomialFeatures(degree=1)
X_train_poly = poly.fit_transform(X_train)

model = LinearRegression()
model.fit(X_train_poly, y_train)  # â† Ã–ÄRENME BURASI!
```

**Model ne Ã¶ÄŸreniyor?**
```
CO = Î²â‚€ + Î²â‚Ã—T + Î²â‚‚Ã—RH + Î²â‚ƒÃ—AH

Ã–rnek:
CO = 0.5 + 0.03Ã—T + 0.01Ã—RH + 0.8Ã—AH
```

Model, **en iyi Î² deÄŸerlerini** buluyor!

**NasÄ±l Ã¶ÄŸreniyor? (BasitleÅŸtirilmiÅŸ)**
```
1. Random Î² deÄŸerleriyle baÅŸla
   CO_tahmin = 0.2 + 0.05Ã—T + 0.02Ã—RH + 0.5Ã—AH

2. Tahminleri yap
   GerÃ§ek CO: 2.6  â†’  Tahmin: 2.1  â†’  Hata: 0.5
   GerÃ§ek CO: 2.0  â†’  Tahmin: 1.8  â†’  Hata: 0.2
   ...

3. Toplam hatayÄ± hesapla
   MSE = (0.5Â² + 0.2Â² + ...) / 5140 = 2.04

4. Î²'larÄ± deÄŸiÅŸtir, hatayÄ± azalt!
   (Gradient Descent algoritmasÄ±)

5. En dÃ¼ÅŸÃ¼k hata bulunana kadar tekrarla!
```

**SonuÃ§:** Model, **optimal Î² deÄŸerlerini** buldu!

##### Degree 2 (Quadratic - Daha KarmaÅŸÄ±k)

```python
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
```

**Åimdi ne Ã¶ÄŸreniyor?**
```
CO = Î²â‚€ + Î²â‚Ã—T + Î²â‚‚Ã—RH + Î²â‚ƒÃ—AH
     + Î²â‚„Ã—TÂ² + Î²â‚…Ã—TÃ—RH + Î²â‚†Ã—TÃ—AH
     + Î²â‚‡Ã—RHÂ² + Î²â‚ˆÃ—RHÃ—AH + Î²â‚‰Ã—AHÂ²
```

**Fark:**
- Degree 1: 3 terim (T, RH, AH)
- Degree 2: 9 terim (artÄ± kareler ve Ã§arpÄ±mlar!)
- Daha karmaÅŸÄ±k iliÅŸkileri yakalayabilir!

##### Degree 3, 4, 5... 10

Her degree'de daha da karmaÅŸÄ±k!
- Degree 3: 19 terim
- Degree 10: 364 terim!

**Soru:** Hangisi en iyi?
**Cevap:** Lab 5'in ana konusu! (bias-variance tradeoff)

#### **BÃ¶lÃ¼m 5: Tahmin Yapma** ğŸ”®

```python
# Test verisinde tahmin yap
y_test_pred = model.predict(X_test_poly)
```

**Ne oluyor?**
```
Test Verisi (model HÄ°Ã‡ gÃ¶rmedi!):
   T=15Â°C, RH=52%, AH=0.9 g/mÂ³

Model: "Hmm... Ã¶ÄŸrendiÄŸim formÃ¼lle hesaplayayÄ±m..."
   CO = 0.5 + 0.03Ã—15 + 0.01Ã—52 + 0.8Ã—0.9
   CO = 0.5 + 0.45 + 0.52 + 0.72
   CO = 2.19 mg/mÂ³

GerÃ§ek deÄŸer: 2.3 mg/mÂ³
Hata: |2.19 - 2.3| = 0.11 mg/mÂ³
```

Model, 2,204 test Ã¶rneÄŸi iÃ§in bunu yapÄ±yor!

#### **BÃ¶lÃ¼m 6: DeÄŸerlendirme** ğŸ“Š

```python
# HatayÄ± hesapla
test_mse = mean_squared_error(y_test, y_test_pred)
```

**MSE (Mean Squared Error) nedir?**

```
MSE = (hataâ‚Â² + hataâ‚‚Â² + ... + hataâ‚‚â‚‚â‚€â‚„Â²) / 2204

Ã–rnek:
Hataâ‚ = 0.11  â†’  0.11Â² = 0.0121
Hataâ‚‚ = -0.25 â†’  0.25Â² = 0.0625
Hataâ‚ƒ = 0.08  â†’  0.08Â² = 0.0064
...

MSE = (0.0121 + 0.0625 + 0.0064 + ...) / 2204 = 1.98
```

**DÃ¼ÅŸÃ¼k MSE = Ä°yi model!**

---

## ğŸ”„ Training vs Testing - Derinlemesine

### Neden Ä°kiye AyÄ±rÄ±yoruz?

#### Senaryo 1: TÃ¼m Veriyle EÄŸitsek Ne Olur? âŒ

```python
# YANLIÅ: TÃ¼m veriyi eÄŸitimde kullanalÄ±m
model.fit(tÃ¼m_veri, tÃ¼m_CO_deÄŸerleri)

# Test edelim
hata = model.predict(tÃ¼m_veri)
print(f"Hata: {hata}")  # Ã‡ok dÃ¼ÅŸÃ¼k!
```

**Sorun:** Model **gÃ¶rdÃ¼ÄŸÃ¼ veride** test ediliyor!
- Ezberlemis olabilir!
- **Yeni verilerle** ne olacak bilmiyoruz!

**Analoji:**
```
Ã–ÄŸrenci: SÄ±nav sorularÄ±nÄ± Ã¶nceden gÃ¶rmÃ¼ÅŸ
SÄ±navda: %100 yapÄ±yor (ama ezberlemiÅŸ!)
Yeni konuda: HiÃ§bir ÅŸey bilmiyor!
```

#### Senaryo 2: Train-Test Split âœ…

```python
# DOÄRU: Veriyi ayÄ±r
EÄŸitim: 5,140 veri  # Model bunlarla Ã¶ÄŸrenir
Test:   2,204 veri  # Model HÄ°Ã‡ gÃ¶rmez!

model.fit(eÄŸitim_verisi)
hata = model.predict(test_verisi)
```

**Avantaj:** **GerÃ§ek performans** gÃ¶rÃ¼yoruz!
- Model test verisini HÄ°Ã‡ gÃ¶rmedi
- Yeni verilerdeki baÅŸarÄ±yÄ± simÃ¼le ediyor!

**Analoji:**
```
Ã–ÄŸrenci: Sadece ders kitabÄ±ndaki Ã¶rnekleri Ã§alÄ±ÅŸtÄ±
SÄ±navda: FarklÄ± sorular (ama aynÄ± konudan)
BaÅŸarÄ±: GerÃ§ek Ã¶ÄŸrenmeyi gÃ¶steriyor!
```

---

## ğŸ“ˆ Lab 5'te Ne Buluyoruz?

### 10 FarklÄ± Model

```python
for degree in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:
    # Her degree iÃ§in model eÄŸit
    model = train_polynomial_model(degree)

    # EÄŸitim hatasÄ±
    train_error = hesapla(eÄŸitim_verisi)

    # Test hatasÄ±
    test_error = hesapla(test_verisi)
```

### SonuÃ§lar

| Degree | EÄŸitim HatasÄ± | Test HatasÄ± | Yorum |
|--------|---------------|-------------|-------|
| 1      | 2.04          | 2.06        | Ä°kisi de yÃ¼ksek (Ã§ok basit!) |
| 2      | 2.02          | 2.03        | Biraz dÃ¼ÅŸtÃ¼ |
| ...    | ...           | ...         | ... |
| 9      | 1.95          | 1.98        | Test en dÃ¼ÅŸÃ¼k! â­ |
| 10     | 1.94          | 1.99        | EÄŸitim dÃ¼ÅŸÃ¼k ama test arttÄ±! |

**Bulgu:**
- **Degree 9**: En iyi genelleme!
- **Degree 10**: EÄŸitim Ã§ok iyi, test kÃ¶tÃ¼ â†’ Overfitting!

---

## ğŸ¯ Yapay Zeka Ä°ÅŸ BaÅŸÄ±nda: GerÃ§ek Ã–rnek

### AdÄ±m AdÄ±m Bir Tahmin

```python
# 1. YENÄ° BÄ°R VERÄ° GELDÄ°
yeni_olcum = {
    'T': 22.5,   # SÄ±caklÄ±k
    'RH': 58.0,  # BaÄŸÄ±l nem
    'AH': 1.15   # Mutlak nem
}

# 2. MODELÄ° HAZIRLA (Degree 9 - en iyisi!)
poly = PolynomialFeatures(degree=9)
X_new_poly = poly.transform([[22.5, 58.0, 1.15]])
# [22.5, 58.0, 1.15, 22.5Â², 22.5Ã—58, ..., 1.15â¹]

# 3. TAHMÄ°N YAP
CO_tahmini = model.predict(X_new_poly)
print(f"Tahmini CO: {CO_tahmini[0]:.2f} mg/mÂ³")
# Ã‡Ä±ktÄ±: Tahmini CO: 2.34 mg/mÂ³
```

**Model ne yaptÄ±?**
```
1. Ã–ÄŸrendiÄŸi formÃ¼lÃ¼ kullandÄ±:
   CO = Î²â‚€ + Î²â‚Ã—22.5 + Î²â‚‚Ã—58.0 + Î²â‚ƒÃ—1.15 + ...
        + Î²â‚ƒâ‚†â‚„Ã—(1.15â¹)

2. 364 terimi hesapladÄ±

3. SonuÃ§: 2.34 mg/mÂ³
```

**Bu bir AI tahmini!**
- Model, 5,140 Ã¶rnekten **Ã¶ÄŸrendi**
- HiÃ§ gÃ¶rmediÄŸi yeni veriye **uyguladÄ±**
- Ä°nsan mÃ¼dahalesi olmadan **karar verdi**!

---

## ğŸ§  Model NasÄ±l Ã–ÄŸreniyor? (DetaylÄ±)

### Linear Regression'Ä±n MatematiÄŸi

**AmaÃ§:** En iyi Î² deÄŸerlerini bul!

```
Minimize et: MSE = Î£(gerÃ§ek - tahmin)Â² / n

Tahmin = Î²â‚€ + Î²â‚Ã—T + Î²â‚‚Ã—RH + Î²â‚ƒÃ—AH
```

**Ã‡Ã¶zÃ¼m YÃ¶ntemi: Normal Equation**
```
Î² = (Xáµ€X)â»Â¹Xáµ€y
```

Sklearn bunu sizin iÃ§in yapÄ±yor!

### Gradient Descent (Alternatif)

**Benzetme:** KaranlÄ±kta daÄŸdan inme

```
1. Rastgele bir noktadan baÅŸla (random Î²)
2. Hangi yÃ¶n aÅŸaÄŸÄ±? (gradient hesapla)
3. O yÃ¶ne kÃ¼Ã§Ã¼k adÄ±m at
4. Tekrarla â†’ En alÃ§ak noktayÄ± bul!
```

**Lab 5'te:**
- Sklearn otomatik yapÄ±yor
- Normal Equation kullanÄ±yor (kÃ¼Ã§Ã¼k veriler iÃ§in hÄ±zlÄ±)

---

## ğŸ“Š GÃ¶rselleÅŸtirme

### Model Ã–ÄŸrenmeden Ã–nce

```
CO â†‘ GerÃ§ek veriler
   |    Ã—
   |      Ã—  Ã—
   |  Ã—     Ã—   Ã—
   |   Ã—       Ã—
   |________________â†’ SÄ±caklÄ±k

Model: "Hmm... ne yapacaÄŸÄ±mÄ± bilmiyorum"
```

### Model Ã–ÄŸrendikten Sonra (Degree 1)

```
CO â†‘
   |    Ã—
   |      Ã—/ Ã—  â† Tahmin Ã§izgisi
   |  Ã— /   Ã—   Ã—
   |   /Ã—      Ã—
   |/_____________â†’ SÄ±caklÄ±k

Model: "DÃ¼z bir Ã§izgi Ã§izdim, yaklaÅŸÄ±k doÄŸru!"
```

### Degree 9 (En Ä°yi)

```
CO â†‘
   |    Ã—
   |   ~~~Ã—~~Ã—  â† Daha iyi uyum
   |  Ã— ~~  Ã— ~~Ã—
   |   ~~Ã—    ~~Ã—
   |/_____________â†’ SÄ±caklÄ±k

Model: "EÄŸriyi takip ediyorum, daha iyi!"
```

### Degree 10 (Overfitting)

```
CO â†‘
   |    Ã—
   | /\/\Ã—/\Ã—  â† Ã‡ok karmaÅŸÄ±k!
   |Ã—/\/  Ã— /\Ã—
   | \/Ã—  \/  Ã—
   |/_____________â†’ SÄ±caklÄ±k

Model: "Her noktaya dokun... ama test verisinde kÃ¶tÃ¼!"
```

---

## ğŸ¯ Ã–zet: AI'nÄ±n Lab 5'teki RolÃ¼

### 1. **Ã–ÄŸrenme** (Training)
```python
model.fit(X_train, y_train)
# 5,140 Ã¶rnekten iliÅŸkileri Ã¶ÄŸren!
```

### 2. **Tahmin** (Prediction)
```python
predictions = model.predict(X_test)
# Yeni 2,204 Ã¶rneÄŸi tahmin et!
```

### 3. **DeÄŸerlendirme** (Evaluation)
```python
mse = mean_squared_error(y_test, predictions)
# Ne kadar iyiyim?
```

### 4. **Optimizasyon** (Model Selection)
```
Degree 1, 2, 3... 10 dene
En iyi test performansÄ±nÄ± bul!
```

---

## ğŸ’¡ Neden Bu AI/ML SayÄ±lÄ±yor?

### Klasik Programlama

```python
def predict_CO(T, RH, AH):
    if T > 25 and RH < 50:
        return 2.5
    elif T < 15 and RH > 70:
        return 1.8
    # ... 1000 tane kural!
```

âŒ **Sorun:** KurallarÄ± elle yazmanÄ±z gerekiyor!

### Machine Learning (Lab 5)

```python
model.fit(veriler, CO_deÄŸerleri)
prediction = model.predict(yeni_veri)
```

âœ… **Ã‡Ã¶zÃ¼m:** Model **kendisi Ã¶ÄŸreniyor**!

**Fark:**
- **Klasik:** Siz kurallarÄ± yazÄ±yorsunuz
- **ML:** Model kurallarÄ± **kendisi keÅŸfediyor**!

---

## ğŸš€ Sonraki AdÄ±m

Åimdi **"Kod AÃ§Ä±klamalarÄ±"** belgesine geÃ§in ve her satÄ±rÄ±n **tam olarak ne yaptÄ±ÄŸÄ±nÄ±** gÃ¶rÃ¼n!

---

**HazÄ±rlayan:** Muhammed Ali KarataÅŸ (2021403030)
**Tarih:** 12 KasÄ±m 2025
