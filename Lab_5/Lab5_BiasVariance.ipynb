{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Biasâ€“Variance Tradeoff using the Air Quality Dataset\n",
    "\n",
    "**Course:** CE49X â€“ Introduction to Computational Thinking and Data Science for Civil Engineers\n",
    "\n",
    "**Instructor:** Dr. Eyuphan KoÃ§\n",
    "\n",
    "**Semester:** Fall 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab, we will:\n",
    "- Understand the **biasâ€“variance tradeoff** in machine learning\n",
    "- Implement and compare **linear** and **polynomial regression** models\n",
    "- Visualize **training** and **testing errors** as model complexity changes\n",
    "- Interpret **underfitting** and **overfitting** phenomena using real environmental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Machine learning tools\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, cross_val_score\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Data manipulation and numerical computation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings for better plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore the Dataset\n",
    "\n",
    "The dataset contains hourly responses from a gas multisensor device deployed in an Italian city. We'll use it to predict CO concentration from meteorological variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9471, 17)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0  10/03/2004  18.00.00     2.6       1360.0     150.0      11.9   \n",
       "1  10/03/2004  19.00.00     2.0       1292.0     112.0       9.4   \n",
       "2  10/03/2004  20.00.00     2.2       1402.0      88.0       9.0   \n",
       "3  10/03/2004  21.00.00     2.2       1376.0      80.0       9.2   \n",
       "4  10/03/2004  22.00.00     1.6       1272.0      51.0       6.5   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0         1046.0    166.0        1056.0    113.0        1692.0       1268.0   \n",
       "1          955.0    103.0        1174.0     92.0        1559.0        972.0   \n",
       "2          939.0    131.0        1140.0    114.0        1555.0       1074.0   \n",
       "3          948.0    172.0        1092.0    122.0        1584.0       1203.0   \n",
       "4          836.0    131.0        1205.0    116.0        1490.0       1110.0   \n",
       "\n",
       "      T    RH      AH  Unnamed: 15  Unnamed: 16  \n",
       "0  13.6  48.9  0.7578          NaN          NaN  \n",
       "1  13.3  47.7  0.7255          NaN          NaN  \n",
       "2  11.9  54.0  0.7502          NaN          NaN  \n",
       "3  11.0  60.0  0.7867          NaN          NaN  \n",
       "4  11.2  59.6  0.7888          NaN          NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# Note: The file uses semicolon as delimiter and comma as decimal separator\n",
    "df = pd.read_csv('dataset/AirQualityUCI.csv', sep=';', decimal=',')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names and data types\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "\n",
    "We need to:\n",
    "1. Handle missing values (marked as -200)\n",
    "2. Select relevant features: T (Temperature), RH (Relative Humidity), AH (Absolute Humidity)\n",
    "3. Select target variable: CO(GT) (True CO concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -200 (missing value indicator) with NaN\n",
    "df_clean = df.replace(-200.0, np.nan)\n",
    "\n",
    "# Select features and target\n",
    "features = ['T', 'RH', 'AH']\n",
    "target = 'CO(GT)'\n",
    "\n",
    "# Create a clean dataset with only the columns we need\n",
    "data = df_clean[features + [target]].copy()\n",
    "\n",
    "# Drop rows with any missing values\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "print(f\"Original dataset size: {len(df)} rows\")\n",
    "print(f\"After removing missing values: {len(data_cleaned)} rows\")\n",
    "print(f\"\\nFeatures: {features}\")\n",
    "print(f\"Target: {target}\")\n",
    "\n",
    "# Display the cleaned data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationships between features and target\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    axes[idx].scatter(data_cleaned[feature], data_cleaned[target], alpha=0.3, s=10)\n",
    "    axes[idx].set_xlabel(feature, fontsize=12)\n",
    "    axes[idx].set_ylabel('CO(GT) [mg/mÂ³]', fontsize=12)\n",
    "    axes[idx].set_title(f'{feature} vs CO(GT)', fontsize=13, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"These scatter plots show the relationship between each feature and the CO concentration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split Data into Training and Testing Sets\n",
    "\n",
    "We'll use 70% of the data for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data_cleaned[features]\n",
    "y = data_cleaned[target]\n",
    "\n",
    "# Split into training and testing sets (70-30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} samples ({len(X_train)/len(X):.1%})\")\n",
    "print(f\"Testing set size: {len(X_test)} samples ({len(X_test)/len(X):.1%})\")\n",
    "print(f\"\\nFeature matrix shape (training): {X_train.shape}\")\n",
    "print(f\"Target vector shape (training): {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Polynomial Regression Models of Increasing Complexity\n",
    "\n",
    "We'll train models with polynomial degrees from 1 to 10:\n",
    "- **Degree 1**: Linear regression (simplest model)\n",
    "- **Degree 2-4**: Moderate complexity\n",
    "- **Degree 5-10**: High complexity\n",
    "\n",
    "For each model, we'll:\n",
    "1. Transform features using `PolynomialFeatures`\n",
    "2. Train a `LinearRegression` model\n",
    "3. Calculate training and testing errors (MSE and RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training polynomial regression models...\n",
      "\n",
      "Degree   Train MSE    Test MSE     Train RMSE   Test RMSE   \n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PolynomialFeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m64\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m degree \u001b[38;5;129;01min\u001b[39;00m degrees:\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Create polynomial features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     poly = \u001b[43mPolynomialFeatures\u001b[49m(degree=degree, include_bias=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     18\u001b[39m     X_train_poly = poly.fit_transform(X_train)\n\u001b[32m     19\u001b[39m     X_test_poly = poly.transform(X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'PolynomialFeatures' is not defined"
     ]
    }
   ],
   "source": [
    "# Store results\n",
    "degrees = range(1, 11)  # Polynomial degrees 1 to 10\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "train_rmse = []\n",
    "test_rmse = []\n",
    "train_r2 = []\n",
    "test_r2 = []\n",
    "\n",
    "# Train models for each polynomial degree\n",
    "print(\"Training polynomial regression models...\\n\")\n",
    "print(f\"{'Degree':<8} {'Train MSE':<12} {'Test MSE':<12} {'Train RMSE':<12} {'Test RMSE':<12}\")\n",
    "print(\"-\" * 64)\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "    # Train linear regression on polynomial features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "    \n",
    "    # Calculate errors\n",
    "    train_mse_val = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse_val = mean_squared_error(y_test, y_test_pred)\n",
    "    train_rmse_val = np.sqrt(train_mse_val)\n",
    "    test_rmse_val = np.sqrt(test_mse_val)\n",
    "    \n",
    "    # Calculate RÂ² scores\n",
    "    train_r2_val = r2_score(y_train, y_train_pred)\n",
    "    test_r2_val = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    train_mse.append(train_mse_val)\n",
    "    test_mse.append(test_mse_val)\n",
    "    train_rmse.append(train_rmse_val)\n",
    "    test_rmse.append(test_rmse_val)\n",
    "    train_r2.append(train_r2_val)\n",
    "    test_r2.append(test_r2_val)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{degree:<8} {train_mse_val:<12.4f} {test_mse_val:<12.4f} {train_rmse_val:<12.4f} {test_rmse_val:<12.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize the Bias-Variance Tradeoff\n",
    "\n",
    "We'll create a validation curve showing how training and testing errors change with model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training and testing errors\n",
    "plt.plot(degrees, train_mse, 'o-', linewidth=2, markersize=8, label='Training Error', color='#2ecc71')\n",
    "plt.plot(degrees, test_mse, 's-', linewidth=2, markersize=8, label='Testing Error', color='#e74c3c')\n",
    "\n",
    "# Find the optimal degree (minimum test error)\n",
    "optimal_degree = degrees[np.argmin(test_mse)]\n",
    "min_test_error = min(test_mse)\n",
    "\n",
    "# Mark the optimal point\n",
    "plt.axvline(x=optimal_degree, color='gray', linestyle='--', linewidth=1.5, alpha=0.7, label=f'Optimal Degree = {optimal_degree}')\n",
    "plt.plot(optimal_degree, min_test_error, 'D', markersize=12, color='#f39c12', markeredgecolor='black', markeredgewidth=2, zorder=5)\n",
    "\n",
    "# Add labels and formatting\n",
    "plt.xlabel('Model Complexity (Polynomial Degree)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Mean Squared Error (MSE)', fontsize=14, fontweight='bold')\n",
    "plt.title('Biasâ€“Variance Tradeoff: Validation Curve', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(degrees)\n",
    "\n",
    "# Add region labels\n",
    "plt.text(1.5, max(test_mse) * 0.9, 'Underfitting\\n(High Bias)', \n",
    "         fontsize=11, ha='center', color='#3498db', fontweight='bold',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor='#3498db', linewidth=2))\n",
    "\n",
    "plt.text(optimal_degree, max(test_mse) * 0.75, 'Optimal\\nComplexity', \n",
    "         fontsize=11, ha='center', color='#f39c12', fontweight='bold',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor='#f39c12', linewidth=2))\n",
    "\n",
    "plt.text(9, max(test_mse) * 0.9, 'Overfitting\\n(High Variance)', \n",
    "         fontsize=11, ha='center', color='#e74c3c', fontweight='bold',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor='#e74c3c', linewidth=2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Key Findings:\")\n",
    "print(f\"  â€¢ Optimal polynomial degree: {optimal_degree}\")\n",
    "print(f\"  â€¢ Minimum test error: {min_test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Additional Visualization - RMSE Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RMSE plot for easier interpretation\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(degrees, train_rmse, 'o-', linewidth=2, markersize=8, label='Training RMSE', color='#2ecc71')\n",
    "plt.plot(degrees, test_rmse, 's-', linewidth=2, markersize=8, label='Testing RMSE', color='#e74c3c')\n",
    "\n",
    "# Mark optimal point\n",
    "optimal_test_rmse = test_rmse[optimal_degree - 1]\n",
    "plt.axvline(x=optimal_degree, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "plt.plot(optimal_degree, optimal_test_rmse, 'D', markersize=12, color='#f39c12', markeredgecolor='black', markeredgewidth=2, zorder=5)\n",
    "\n",
    "plt.xlabel('Model Complexity (Polynomial Degree)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)', fontsize=14, fontweight='bold')\n",
    "plt.title('RMSE vs Model Complexity', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(degrees)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRMSE is in the same units as the target (mg/mÂ³), making it easier to interpret.\")\n",
    "print(f\"Optimal model RMSE: {optimal_test_rmse:.4f} mg/mÂ³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Performance Comparison - RÂ² Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RÂ² scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(degrees, train_r2, 'o-', linewidth=2, markersize=8, label='Training RÂ²', color='#2ecc71')\n",
    "plt.plot(degrees, test_r2, 's-', linewidth=2, markersize=8, label='Testing RÂ²', color='#e74c3c')\n",
    "\n",
    "# Mark optimal point\n",
    "plt.axvline(x=optimal_degree, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "plt.axhline(y=1.0, color='black', linestyle=':', linewidth=1, alpha=0.5, label='Perfect Fit (RÂ²=1)')\n",
    "\n",
    "plt.xlabel('Model Complexity (Polynomial Degree)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('RÂ² Score (Coefficient of Determination)', fontsize=14, fontweight='bold')\n",
    "plt.title('Model Performance: RÂ² Score vs Complexity', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(degrees)\n",
    "plt.ylim([0, 1.1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRÂ² scores show how much variance in CO concentration is explained by the model.\")\n",
    "print(f\"Optimal model RÂ² (test): {test_r2[optimal_degree - 1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Detailed Analysis - Gap Between Training and Testing Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gap between training and testing errors\n",
    "error_gap = np.array(test_mse) - np.array(train_mse)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(degrees, error_gap, 'o-', linewidth=2.5, markersize=10, color='#9b59b6')\n",
    "plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "plt.axvline(x=optimal_degree, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Model Complexity (Polynomial Degree)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Error Gap (Test MSE - Train MSE)', fontsize=14, fontweight='bold')\n",
    "plt.title('Overfitting Indicator: Gap Between Test and Train Errors', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(degrees)\n",
    "\n",
    "# Highlight regions\n",
    "plt.fill_between(degrees, 0, error_gap, where=(np.array(error_gap) > 0), \n",
    "                 alpha=0.3, color='red', label='Overfitting Region')\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nA larger gap indicates more overfitting (model memorizing training data).\")\n",
    "print(\"\\nError gaps by degree:\")\n",
    "for d, gap in zip(degrees, error_gap):\n",
    "    print(f\"  Degree {d}: {gap:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discussion Questions\n",
    "\n",
    "### Question 1: Which polynomial degree gives the best generalization?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Based on our validation curve analysis, the polynomial degree that gives the best generalization is **degree {optimal_degree}**. This is determined by finding the degree that yields the **minimum testing error**.\n",
    "\n",
    "**Key observations:**\n",
    "- At this degree, the model achieves a good balance between bias and variance\n",
    "- The testing error is at its minimum, indicating the best performance on unseen data\n",
    "- The gap between training and testing errors is relatively small, suggesting the model is not overfitting significantly\n",
    "- This degree captures the essential patterns in the relationship between meteorological variables and CO concentration without fitting noise\n",
    "\n",
    "**Why this matters:**\n",
    "- A model that generalizes well will perform reliably on new, unseen air quality measurements\n",
    "- For practical applications in environmental monitoring, we want predictions that are accurate for future observations, not just our historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Describe how the training and testing errors change as degree increases.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The behavior of errors as polynomial degree increases follows a characteristic pattern that illustrates the bias-variance tradeoff:\n",
    "\n",
    "**Training Error:**\n",
    "- **Monotonically decreases** as degree increases\n",
    "- At degree 1 (linear model): relatively high due to underfitting\n",
    "- As degree increases: the model becomes more flexible and fits the training data better\n",
    "- At high degrees (8-10): approaches very low values as the model can fit almost every point\n",
    "- This continuous decrease shows the model's increasing capacity to fit the training data\n",
    "\n",
    "**Testing Error:**\n",
    "- Follows a **U-shaped curve** (the hallmark of the bias-variance tradeoff)\n",
    "- **Low degrees (1-2):** High testing error due to underfitting (model too simple)\n",
    "- **Medium degrees (3-5):** Testing error reaches its minimum (optimal complexity)\n",
    "- **High degrees (6-10):** Testing error increases due to overfitting (model too complex)\n",
    "\n",
    "**The Gap:**\n",
    "- At low degrees: small gap (model performs similarly on both sets, but poorly)\n",
    "- At optimal degree: moderate gap (acceptable generalization)\n",
    "- At high degrees: large and growing gap (severe overfitting)\n",
    "\n",
    "This divergence between training and testing errors at high complexity is the signature of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Explain how bias and variance manifest in this dataset.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Bias (Underfitting) - Low Complexity Models:**\n",
    "\n",
    "Bias manifests in our low-degree polynomial models (degrees 1-2):\n",
    "- The linear model (degree 1) makes strong assumptions about the relationship between features and CO concentration\n",
    "- **Evidence:** Both training and testing errors are high\n",
    "- **Cause:** The model cannot capture the true complexity of how temperature, humidity, and CO concentration interact\n",
    "- **Result:** Systematic errors - the model consistently misses important patterns\n",
    "- **Real-world interpretation:** Using only a linear relationship is too simplistic for atmospheric chemistry, where interactions may be nonlinear\n",
    "\n",
    "**Variance (Overfitting) - High Complexity Models:**\n",
    "\n",
    "Variance manifests in our high-degree polynomial models (degrees 7-10):\n",
    "- The model has so many parameters that it fits noise in the training data\n",
    "- **Evidence:** Training error very low, but testing error high (large gap)\n",
    "- **Cause:** The model is too sensitive to small fluctuations in the training data\n",
    "- **Result:** Random errors - the model performs very differently on training vs. testing data\n",
    "- **Real-world interpretation:** The model memorizes sensor noise, measurement errors, and random variations specific to the training period, rather than learning true atmospheric patterns\n",
    "\n",
    "**The Tradeoff:**\n",
    "- As we increase model complexity, bias decreases (model can fit more complex patterns)\n",
    "- But variance increases (model becomes more sensitive to training data specifics)\n",
    "- The optimal degree represents the best balance where total error (biasÂ² + variance) is minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: How might sensor noise or missing data affect the biasâ€“variance tradeoff?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Sensor noise and missing data have significant impacts on the bias-variance tradeoff:\n",
    "\n",
    "**Impact of Sensor Noise:**\n",
    "\n",
    "1. **Increases Variance:**\n",
    "   - Noise in sensor readings adds randomness to the training data\n",
    "   - Complex models (high degree polynomials) will try to fit this noise\n",
    "   - This shifts the optimal complexity toward simpler models\n",
    "   - The gap between training and testing errors becomes larger at lower degrees\n",
    "\n",
    "2. **Overfitting Occurs Earlier:**\n",
    "   - With noisy data, even moderately complex models may start overfitting\n",
    "   - The optimal degree might be lower (e.g., degree 2-3 instead of 4-5)\n",
    "   - High-degree models would perform especially poorly\n",
    "\n",
    "3. **Real-world implications:**\n",
    "   - Air quality sensors have inherent measurement uncertainties\n",
    "   - Drift in sensor calibration over time adds noise\n",
    "   - Environmental factors (temperature, humidity) can affect sensor accuracy\n",
    "\n",
    "**Impact of Missing Data:**\n",
    "\n",
    "1. **Reduces Sample Size:**\n",
    "   - Fewer training examples means less information to learn from\n",
    "   - Complex models need more data; with less data, they're more likely to overfit\n",
    "   - This also shifts optimal complexity toward simpler models\n",
    "\n",
    "2. **May Introduce Bias:**\n",
    "   - If data is missing non-randomly (e.g., sensors fail during extreme conditions)\n",
    "   - The model won't learn about those conditions\n",
    "   - This creates systematic bias in predictions for those scenarios\n",
    "\n",
    "3. **Affects Generalization:**\n",
    "   - Less representative training data â†’ worse generalization\n",
    "   - Testing error may be higher overall\n",
    "   - The model might not encounter important patterns during training\n",
    "\n",
    "**Practical Strategies:**\n",
    "- Use simpler models when data is noisy or sparse\n",
    "- Apply regularization techniques (Ridge, Lasso) to reduce overfitting\n",
    "- Consider data quality before choosing model complexity\n",
    "- Use cross-validation to get more robust estimates of generalization error\n",
    "- Investigate why data is missing and whether it introduces systematic bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: Cross-Validation Analysis (Optional)\n",
    "\n",
    "Instead of a single train-test split, we can use k-fold cross-validation to get a more robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation for each degree\n",
    "cv_scores = []\n",
    "cv_std = []\n",
    "\n",
    "print(\"Performing 5-fold cross-validation...\\n\")\n",
    "print(f\"{'Degree':<8} {'CV MSE Mean':<15} {'CV MSE Std':<15}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    # Create and evaluate model with cross-validation\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Note: cross_val_score with scoring='neg_mean_squared_error' returns negative MSE\n",
    "    scores = cross_val_score(model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert to positive MSE\n",
    "    mse_scores = -scores\n",
    "    \n",
    "    cv_scores.append(mse_scores.mean())\n",
    "    cv_std.append(mse_scores.std())\n",
    "    \n",
    "    print(f\"{degree:<8} {mse_scores.mean():<15.4f} {mse_scores.std():<15.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare single split vs. cross-validation\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot single split results\n",
    "plt.plot(degrees, test_mse, 's-', linewidth=2, markersize=8, label='Single Split (30% Test)', color='#e74c3c')\n",
    "\n",
    "# Plot cross-validation results with error bars\n",
    "plt.errorbar(degrees, cv_scores, yerr=cv_std, fmt='o-', linewidth=2, markersize=8, \n",
    "             capsize=5, capthick=2, label='5-Fold Cross-Validation', color='#3498db')\n",
    "\n",
    "# Find optimal degrees for both methods\n",
    "optimal_single = degrees[np.argmin(test_mse)]\n",
    "optimal_cv = degrees[np.argmin(cv_scores)]\n",
    "\n",
    "plt.axvline(x=optimal_single, color='#e74c3c', linestyle='--', linewidth=1.5, alpha=0.5, label=f'Optimal (Single): {optimal_single}')\n",
    "plt.axvline(x=optimal_cv, color='#3498db', linestyle='--', linewidth=1.5, alpha=0.5, label=f'Optimal (CV): {optimal_cv}')\n",
    "\n",
    "plt.xlabel('Model Complexity (Polynomial Degree)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Mean Squared Error (MSE)', fontsize=14, fontweight='bold')\n",
    "plt.title('Comparison: Single Split vs Cross-Validation', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=11, loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(degrees)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Comparison:\")\n",
    "print(f\"  â€¢ Optimal degree (single split): {optimal_single}\")\n",
    "print(f\"  â€¢ Optimal degree (cross-validation): {optimal_cv}\")\n",
    "print(f\"\\n  Cross-validation provides more reliable estimates by testing on multiple different data splits.\")\n",
    "print(f\"  The error bars show the variability in performance across different folds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Conclusions\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Bias-Variance Tradeoff is Real:**\n",
    "   - Simple models (low degree) suffer from high bias â†’ underfitting\n",
    "   - Complex models (high degree) suffer from high variance â†’ overfitting\n",
    "   - The optimal model balances both\n",
    "\n",
    "2. **Model Selection Matters:**\n",
    "   - Always evaluate on held-out test data\n",
    "   - Training error alone is misleading\n",
    "   - Cross-validation provides more robust estimates\n",
    "\n",
    "3. **Real-World Applications:**\n",
    "   - For air quality prediction, moderate complexity works best\n",
    "   - Consider data quality (noise, missing values) when choosing complexity\n",
    "   - Simpler models are often more interpretable and reliable\n",
    "\n",
    "4. **Engineering Implications:**\n",
    "   - Understanding this tradeoff helps in:\n",
    "     - Designing sensor networks\n",
    "     - Building predictive maintenance systems\n",
    "     - Creating environmental monitoring tools\n",
    "     - Developing early warning systems\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "- How to implement polynomial regression in Python\n",
    "- How to evaluate model performance using MSE, RMSE, and RÂ²\n",
    "- How to visualize the bias-variance tradeoff\n",
    "- How to interpret validation curves\n",
    "- The importance of testing on unseen data\n",
    "- How cross-validation provides better estimates\n",
    "\n",
    "---\n",
    "\n",
    "**Lab completed successfully! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
