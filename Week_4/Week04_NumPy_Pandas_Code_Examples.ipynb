{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CE49X: Introduction to Computational Thinking and Data Science for Civil Engineers\n\n## Week 4: NumPy and Pandas\n\n**Based on \"Python Data Science Handbook\" by Jake VanderPlas**\n- **Chapter 2**: Introduction to NumPy\n- **Chapter 3**: Data Manipulation with Pandas (Sections 3.0-3.6)\n\n**Author:** Dr. Eyuphan Koc  \n**Institution:** Bogazici University - Department of Civil Engineering  \n**Semester:** Fall 2025\n\n---\n\n### Topics Covered:\n\n**NumPy:**\n1. **Introduction to NumPy** - Arrays and basic operations\n2. **Array Fundamentals** - Creating, indexing, and reshaping\n3. **Array Operations** - Vectorization and universal functions\n4. **Aggregations** - Statistical operations\n5. **Broadcasting** - Operations on different shapes\n6. **Boolean Operations** - Masking and filtering\n7. **Advanced Indexing** - Fancy indexing\n8. **Sorting** - Organizing data\n9. **Structured Arrays** - Mixed data types\n\n**Pandas:**\n10. **Introduction to Pandas** - DataFrames and why Pandas\n11. **Pandas Core Objects** - Series, DataFrame, Index\n12. **Data Indexing and Selection** - loc, iloc, masking\n13. **Operations in Pandas** - Index alignment and ufuncs\n14. **Handling Missing Data** - NaN, dropna, fillna\n15. **Hierarchical Indexing** - MultiIndex for higher-dimensional data\n16. **Combining Datasets** - concat and append\n\n### Learning Objectives:\n- Understand why NumPy is essential for scientific computing\n- Master NumPy arrays and vectorized operations\n- Learn Pandas DataFrames for labeled, structured data\n- Perform data selection, filtering, and transformation\n- Handle missing data effectively\n- Combine and manipulate datasets\n\n---\n\n*This notebook contains practical examples demonstrating NumPy and Pandas capabilities for numerical computing and data analysis in civil engineering applications.*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to NumPy\n",
    "\n",
    "NumPy (Numerical Python) is the fundamental package for scientific computing in Python. It provides:\n",
    "- Fast, efficient multi-dimensional arrays\n",
    "- Vectorized computations (no loops needed!)\n",
    "- Broadcasting for operations on different shapes\n",
    "- Foundation for Pandas, SciPy, Matplotlib, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Speed Comparison: Lists vs NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.0302s\n"
     ]
    }
   ],
   "source": [
    "# Python list: slow\n",
    "import time\n",
    "L = list(range(1000000))\n",
    "start = time.time()\n",
    "result = [x**2 for x in L]\n",
    "print(f\"Time: {time.time()-start:.4f}s\")\n",
    "# Time: ~0.15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.0015s\n"
     ]
    }
   ],
   "source": [
    "# NumPy array: fast!\n",
    "import numpy as np\n",
    "A = np.arange(1000000)\n",
    "start = time.time()\n",
    "result = A**2\n",
    "print(f\"Time: {time.time()-start:.4f}s\")\n",
    "# Time: ~0.002s  (75x faster!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Installing and Importing NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # ALWAYS use this convention!\n",
    "\n",
    "# Check version\n",
    "print(np.__version__)  # e.g., '1.24.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creating Your First NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# From Python list - 1D array\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "arr = np.array(my_list)\n",
    "print(arr)  # [1 2 3 4 5]\n",
    "\n",
    "# 2D array (matrix)\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "print(matrix)\n",
    "# [[1 2 3]\n",
    "#  [4 5 6]\n",
    "#  [7 8 9]]\n",
    "\n",
    "# Unlike lists, all elements must be same type!\n",
    "mixed = np.array([1, 2.5, 3])  # Will convert to float\n",
    "print(mixed.dtype)  # dtype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Array Fundamentals\n",
    "\n",
    "### 2.1 Creating Arrays: Common Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Zeros - initialize array\n",
    "zeros = np.zeros(10)  # [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "zeros_matrix = np.zeros((3, 3))  # 3x3 matrix of zeros\n",
    "\n",
    "# Ones\n",
    "ones = np.ones(5)  # [1. 1. 1. 1. 1.]\n",
    "fives = np.ones(5) * 5  # [5. 5. 5. 5. 5.]\n",
    "\n",
    "# Sequential values\n",
    "seq = np.arange(0, 11, 2)  # [0 2 4 6 8 10]  (start, stop, step)\n",
    "\n",
    "# Evenly spaced values\n",
    "linear = np.linspace(0, 1, 5)  # [0.  0.25  0.5  0.75  1.] (start, stop, count)\n",
    "\n",
    "# Random values\n",
    "random_vals = np.random.random(5)  # 5 random values between 0 and 1\n",
    "random_ints = np.random.randint(0, 10, size=5)  # 5 random integers 0-9\n",
    "\n",
    "# Identity matrix\n",
    "I = np.eye(3)  # [[1. 0. 0.], [0. 1. 0.], [0. 0. 1.]]\n",
    "\n",
    "print(\"Zeros:\", zeros)\n",
    "print(\"Sequential:\", seq)\n",
    "print(\"Linear:\", linear)\n",
    "print(\"Identity:\")\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Array Attributes: Understanding Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)  # for reproducibility\n",
    "\n",
    "# Create arrays of different dimensions\n",
    "x1 = np.random.randint(10, size=6)  # 1D array\n",
    "x2 = np.random.randint(10, size=(3, 4))  # 2D array\n",
    "x3 = np.random.randint(10, size=(3, 4, 5))  # 3D array\n",
    "\n",
    "print(\"x3 ndim: \", x3.ndim)  # 3\n",
    "print(\"x3 shape:\", x3.shape)  # (3, 4, 5)\n",
    "print(\"x3 size: \", x3.size)  # 60\n",
    "\n",
    "print(\"dtype:\", x3.dtype)  # int64\n",
    "print(\"itemsize:\", x3.itemsize, \"bytes\")  # 8 bytes\n",
    "print(\"nbytes:\", x3.nbytes, \"bytes\")  # 480 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Types in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify dtype at creation\n",
    "arr = np.array([1, 2, 3], dtype=np.float32)\n",
    "\n",
    "# Convert dtype\n",
    "arr_float64 = arr.astype(np.float64)\n",
    "\n",
    "print(arr.dtype)        # float32\n",
    "print(arr_float64.dtype)  # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory comparison\n",
    "a32 = np.ones(1000000, dtype=np.float32)\n",
    "a64 = np.ones(1000000, dtype=np.float64)\n",
    "\n",
    "print(f\"32-bit: {a32.nbytes/1e6} MB\")\n",
    "# 4.0 MB\n",
    "print(f\"64-bit: {a64.nbytes/1e6} MB\")\n",
    "# 8.0 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Indexing and Slicing: Accessing Array Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1D array - similar to Python lists\n",
    "x = np.arange(10)  # [0 1 2 3 4 5 6 7 8 9]\n",
    "print(x[0])      # 0 (first element)\n",
    "print(x[-1])     # 9 (last element)\n",
    "print(x[4:7])    # [4 5 6] (slice from index 4 to 6)\n",
    "print(x[::2])    # [0 2 4 6 8] (every 2nd element)\n",
    "print(x[::-1])   # [9 8 7 6 5 4 3 2 1 0] (reverse)\n",
    "\n",
    "# 2D array - row, column indexing\n",
    "x2 = np.array([[12, 5, 2, 4],\n",
    "               [7, 6, 8, 8],\n",
    "               [1, 6, 7, 7]])\n",
    "\n",
    "print(x2[0, 0])    # 12 (element at row 0, col 0)\n",
    "print(x2[2, -1])   # 7 (element at row 2, last column)\n",
    "print(x2[0, :])    # [12  5  2  4] (first row)\n",
    "print(x2[:, 1])    # [5 6 6] (second column)\n",
    "print(x2[:2, :2])  # [[12  5], [ 7  6]] (2x2 subarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Array Views vs Copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 999   3   4   5]\n",
      "[1 2 3 4 5]\n",
      "[999   3   4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original array\n",
    "original = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# SLICING creates a VIEW (not a copy!)\n",
    "view = original[1:4]\n",
    "view[0] = 999\n",
    "print(original)  # [1 999 3 4 5]  <-- Original changed!\n",
    "\n",
    "# To create independent copy, use .copy()\n",
    "original = np.array([1, 2, 3, 4, 5])\n",
    "independent = original[1:4].copy()\n",
    "independent[0] = 999\n",
    "print(original)  # [1 2 3 4 5]  <-- Original unchanged\n",
    "print(independent)  # [999 3 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Reshaping Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1D to 2D\n",
    "loads = np.arange(12)\n",
    "print(loads)  # [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
    "\n",
    "# Reshape to 3x4 matrix\n",
    "matrix = loads.reshape(3, 4)\n",
    "print(matrix)\n",
    "# [[ 0  1  2  3]\n",
    "#  [ 4  5  6  7]\n",
    "#  [ 8  9 10 11]]\n",
    "\n",
    "# Reshape to 4x3 matrix\n",
    "matrix2 = loads.reshape(4, 3)\n",
    "print(matrix2)\n",
    "# [[ 0  1  2]\n",
    "#  [ 3  4  5]\n",
    "#  [ 6  7  8]\n",
    "#  [ 9 10 11]]\n",
    "\n",
    "# Use -1 to auto-calculate one dimension\n",
    "matrix3 = loads.reshape(2, -1)  # 2 rows, auto-calculate columns\n",
    "print(matrix3.shape)  # (2, 6)\n",
    "\n",
    "# Flatten back to 1D\n",
    "flat = matrix.flatten()  # or .ravel() for view\n",
    "print(flat)  # [ 0  1  2  3  4  5  6  7  8  9 10 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Concatenating and Splitting Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Concatenate 1D arrays\n",
    "dead_load = np.array([10, 15, 20])\n",
    "live_load = np.array([5, 8, 10])\n",
    "total_load = np.concatenate([dead_load, live_load])\n",
    "print(total_load)  # [10 15 20  5  8 10]\n",
    "\n",
    "# Stack vertically (vstack)\n",
    "loads = np.vstack([dead_load, live_load])\n",
    "print(loads)\n",
    "# [[10 15 20]\n",
    "#  [ 5  8 10]]\n",
    "\n",
    "# Stack horizontally (hstack)\n",
    "loads = np.hstack([dead_load, live_load])\n",
    "print(loads)  # [10 15 20  5  8 10]\n",
    "\n",
    "# Split array\n",
    "split_loads = np.split(total_load, [3])  # Split at index 3\n",
    "print(split_loads[0])  # [10 15 20]\n",
    "print(split_loads[1])  # [ 5  8 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Array Operations and Universal Functions\n",
    "\n",
    "### 3.1 Vectorized Arithmetic: No Loops Needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create arrays\n",
    "x = np.arange(4)\n",
    "print(\"x =\", x)  # [0 1 2 3]\n",
    "\n",
    "# Element-wise operations (vectorized - FAST!)\n",
    "print(\"x + 5 =\", x + 5)    # [5 6 7 8]\n",
    "print(\"x - 5 =\", x - 5)    # [-5 -4 -3 -2]\n",
    "print(\"x * 2 =\", x * 2)    # [0 2 4 6]\n",
    "print(\"x / 2 =\", x / 2)    # [0.  0.5 1.  1.5]\n",
    "print(\"x ** 2 =\", x ** 2)  # [0 1 4 9]\n",
    "\n",
    "# Multiple arrays\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([4, 3, 2, 1])\n",
    "print(\"a + b =\", a + b)    # [5 5 5 5]\n",
    "print(\"a * b =\", a * b)    # [4 6 6 4]\n",
    "\n",
    "# Compare to Python list (requires loop!)\n",
    "# result = [x**2 for x in my_list]  # Slow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Universal Functions (ufuncs): Fast Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin(theta) = [0.0000000e+00 1.0000000e+00 1.2246468e-16]\n",
      "cos(theta) = [ 1.000000e+00  6.123234e-17 -1.000000e+00]\n",
      "tan(theta) = [ 0.00000000e+00  1.63312394e+16 -1.22464680e-16]\n",
      "e^x = [ 2.71828183  7.3890561  20.08553692]\n",
      "2^x = [2. 4. 8.]\n",
      "log(x) = [0.         0.69314718 1.09861229]\n",
      "abs(x) = [2 1 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Trigonometric functions\n",
    "theta = np.linspace(0, np.pi, 3)\n",
    "print(\"sin(theta) =\", np.sin(theta))\n",
    "print(\"cos(theta) =\", np.cos(theta))\n",
    "print(\"tan(theta) =\", np.tan(theta))\n",
    "\n",
    "# Exponential and logarithmic\n",
    "x = [1, 2, 3]\n",
    "print(\"e^x =\", np.exp(x))       # [2.718  7.389  20.086]\n",
    "print(\"2^x =\", np.exp2(x))      # [2.  4.  8.]\n",
    "print(\"log(x) =\", np.log(x))    # [0.  0.693  1.099]\n",
    "\n",
    "# Absolute value\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print(\"abs(x) =\", np.abs(x))    # [2 1 0 1 2]\n",
    "\n",
    "# All much faster than Python loops!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Example: Computation on Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute values of sin(x) for many values\n",
    "x = np.linspace(0, np.pi, 3)\n",
    "print(\"x      =\", x)\n",
    "# [0.         1.57079633 3.14159265]\n",
    "\n",
    "print(\"sin(x) =\", np.sin(x))\n",
    "# [0.0000000e+00 1.0000000e+00 1.2246468e-16]\n",
    "\n",
    "# Compute a more complex operation\n",
    "x = np.arange(5)\n",
    "y = np.empty(5)\n",
    "for i in range(5):\n",
    "    y[i] = x[i] ** 2\n",
    "print(y)  # [ 0.  1.  4.  9. 16.]\n",
    "\n",
    "# Much better with vectorization:\n",
    "x = np.arange(5)\n",
    "y = x ** 2\n",
    "print(y)  # [ 0  1  4  9 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregations and Statistics\n",
    "\n",
    "### 4.1 Basic Aggregations: Summarizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Random data\n",
    "L = np.random.random(100)\n",
    "\n",
    "# Summary statistics\n",
    "print(np.sum(L))      # Sum of all values\n",
    "print(np.min(L))      # Minimum value\n",
    "print(np.max(L))      # Maximum value\n",
    "print(np.mean(L))     # Mean\n",
    "print(np.std(L))      # Standard deviation\n",
    "print(np.var(L))      # Variance\n",
    "\n",
    "# These also work as array methods:\n",
    "print(L.sum())\n",
    "print(L.min())\n",
    "print(L.max())\n",
    "print(L.mean())\n",
    "print(L.std())\n",
    "\n",
    "# Percentiles\n",
    "print(np.percentile(L, 25))  # 1st quartile\n",
    "print(np.median(L))          # 50th percentile\n",
    "print(np.percentile(L, 75))  # 3rd quartile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Multi-Dimensional Aggregations: The axis Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 2D array example\n",
    "M = np.random.random((3, 4))\n",
    "print(M)\n",
    "\n",
    "# Aggregate along different axes\n",
    "print(\"Shape:\", M.shape)  # (3, 4)\n",
    "\n",
    "# Sum all values\n",
    "print(M.sum())\n",
    "\n",
    "# Sum along axis 0 (collapse rows -> result has shape (4,))\n",
    "print(M.sum(axis=0))\n",
    "\n",
    "# Sum along axis 1 (collapse columns -> result has shape (3,))\n",
    "print(M.sum(axis=1))\n",
    "\n",
    "# Works with other functions too:\n",
    "print(M.min(axis=0))  # Min of each column\n",
    "print(M.max(axis=1))  # Max of each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 More Aggregation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([10, 15, 20, 25, 30, 35, 40])\n",
    "\n",
    "# Basic stats\n",
    "print(f\"Sum: {np.sum(data)}\")         # 175\n",
    "print(f\"Product: {np.prod(data)}\")    # 3.15e9\n",
    "print(f\"Mean: {np.mean(data)}\")       # 25.0\n",
    "print(f\"Std: {np.std(data)}\")         # 10.0\n",
    "print(f\"Variance: {np.var(data)}\")    # 100.0\n",
    "\n",
    "# Min/Max\n",
    "print(f\"Min: {np.min(data)}\")         # 10\n",
    "print(f\"Max: {np.max(data)}\")         # 40\n",
    "print(f\"Argmin: {np.argmin(data)}\")   # 0 (index of min)\n",
    "print(f\"Argmax: {np.argmax(data)}\")   # 6 (index of max)\n",
    "\n",
    "# Cumulative operations\n",
    "cumsum = np.cumsum(data)  # [10 25 45 70 100 135 175]\n",
    "cumprod = np.cumprod(data[:4])  # [10 150 3000 75000]\n",
    "\n",
    "# Boolean operations\n",
    "print(f\"Any > 50: {np.any(data > 50)}\")    # False\n",
    "print(f\"All > 5: {np.all(data > 5)}\")      # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Example: Analyzing Multi-Dimensional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean: 3.19\n",
      "Std deviation: 0.57\n",
      "Range: 2.30 - 4.10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Precipitation data: 12 months x 5 years\n",
    "precip_data = np.array([\n",
    "    [3.2, 2.8, 3.5, 2.9, 3.1],  # January\n",
    "    [2.5, 2.9, 2.3, 2.7, 2.6],  # February\n",
    "    [3.8, 4.1, 3.6, 4.0, 3.9],  # March\n",
    "    # ... (more months)\n",
    "])\n",
    "\n",
    "# Analysis\n",
    "mean_per_month = np.mean(precip_data, axis=1)\n",
    "mean_per_year = np.mean(precip_data, axis=0)\n",
    "overall_mean = np.mean(precip_data)\n",
    "overall_std = np.std(precip_data)\n",
    "\n",
    "# Find extremes\n",
    "max_precip = np.max(precip_data)\n",
    "min_precip = np.min(precip_data)\n",
    "\n",
    "print(f\"Overall mean: {overall_mean:.2f}\")\n",
    "print(f\"Std deviation: {overall_std:.2f}\")\n",
    "print(f\"Range: {min_precip:.2f} - {max_precip:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Broadcasting\n",
    "\n",
    "Broadcasting allows NumPy to perform operations on arrays of different shapes without explicitly replicating data.\n",
    "\n",
    "### 5.1 Broadcasting Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Scalar + Array (broadcasts scalar to all elements)\n",
    "a = np.array([0, 1, 2])\n",
    "a + 5  # array([5, 6, 7])\n",
    "\n",
    "# 1D + 1D\n",
    "a = np.ones((3, 3))\n",
    "b = np.arange(3)\n",
    "print(a + b)\n",
    "# array([[1., 2., 3.],\n",
    "#        [1., 2., 3.],\n",
    "#        [1., 2., 3.]])\n",
    "\n",
    "# Broadcasting with higher dimensions\n",
    "a = np.arange(3).reshape((3, 1))\n",
    "b = np.arange(3)\n",
    "print(a + b)\n",
    "# [[0 1 2]\n",
    "#  [1 2 3]\n",
    "#  [2 3 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Broadcasting in 2D: Centering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data matrix (10 observations x 3 features)\n",
    "X = np.random.random((10, 3))\n",
    "\n",
    "# Compute mean of each column (feature)\n",
    "Xmean = X.mean(axis=0)\n",
    "\n",
    "# Center the data (subtract mean from each column)\n",
    "X_centered = X - Xmean\n",
    "\n",
    "# Verify mean is now ~0 for each feature\n",
    "print(X_centered.mean(axis=0))\n",
    "# [~0. ~0. ~0.]\n",
    "\n",
    "# This works because Xmean has shape (3,) which broadcasts\n",
    "# to match X's shape (10, 3) by replicating across rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Broadcasting: Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 2D grid using broadcasting\n",
    "x = np.linspace(0, 5, 50)\n",
    "y = np.linspace(0, 5, 50)[:, np.newaxis]\n",
    "\n",
    "# Broadcasting: x is (50,), y is (50,1)\n",
    "# Result z is (50, 50)\n",
    "z = np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)\n",
    "\n",
    "plt.imshow(z, origin='lower', extent=[0, 5, 0, 5],\n",
    "           cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Broadcasting Example')\n",
    "plt.show()\n",
    "\n",
    "# This creates a 2D function from 1D arrays!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Boolean Operations and Masking\n",
    "\n",
    "### 6.1 Comparison Operators: Element-wise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data array\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Comparison operators return boolean arrays\n",
    "print(x < 3)\n",
    "# [ True  True False False False]\n",
    "\n",
    "print(x > 3)\n",
    "# [False False False  True  True]\n",
    "\n",
    "print(x == 3)\n",
    "# [False False  True False False]\n",
    "\n",
    "# Multiple comparisons (use & and |, not 'and' and 'or')\n",
    "print((x > 1) & (x < 5))\n",
    "# [False  True  True  True False]\n",
    "\n",
    "# Count how many satisfy condition\n",
    "print(np.sum(x > 2))  # 3 (True=1, False=0)\n",
    "\n",
    "# Percentage\n",
    "print(np.mean(x > 2))  # 0.6 (60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Boolean Indexing: Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data array\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Create boolean mask\n",
    "mask = x < 3\n",
    "print(mask)\n",
    "# [ True  True False False False]\n",
    "\n",
    "# Use mask to filter data\n",
    "print(x[mask])  # [1 2]\n",
    "\n",
    "# Can use directly without creating variable\n",
    "print(x[x < 3])  # [1 2]\n",
    "\n",
    "# More complex example with 2D\n",
    "np.random.seed(0)\n",
    "X = np.random.randint(10, size=(3, 4))\n",
    "print(X)\n",
    "# [[5 0 3 3]\n",
    "#  [7 9 3 5]\n",
    "#  [2 4 7 6]]\n",
    "\n",
    "print(X[X < 5])  # [0 3 3 3 2 4] (flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Boolean Operators: Combining Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: Rainy days analysis\n",
    "rainfall_inches = np.array([0.2, 0.5, 0.0, 1.2, 0.8, 0.0, 0.3])\n",
    "\n",
    "# Multiple criteria with & (AND) and | (OR)\n",
    "print((rainfall_inches > 0) & (rainfall_inches < 1))\n",
    "# [ True  True False False  True False  True]\n",
    "\n",
    "print((rainfall_inches <= 0) | (rainfall_inches >= 1))\n",
    "# [False False  True  True False  True False]\n",
    "\n",
    "# Use np.sum() to count matches\n",
    "print(np.sum((rainfall_inches > 0) & (rainfall_inches < 1)))  # 4\n",
    "\n",
    "# IMPORTANT: Use & and | for arrays, not 'and' and 'or'!\n",
    "# Also: always use parentheses around conditions\n",
    "\n",
    "# Boolean operators\n",
    "print(~(rainfall_inches > 0.5))  # NOT\n",
    "# [ True False  True False False  True  True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Example: Analyzing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Weather data\n",
    "np.random.seed(1)\n",
    "rainfall = np.random.random(365) * 2  # inches per day\n",
    "\n",
    "# Analysis\n",
    "rainy_days = np.sum(rainfall > 0.5)\n",
    "dry_days = np.sum(rainfall < 0.1)\n",
    "median_precip = np.median(rainfall)\n",
    "mean_precip = np.mean(rainfall)\n",
    "\n",
    "print(f\"Rainy days (>0.5 in): {rainy_days}\")\n",
    "print(f\"Dry days (<0.1 in): {dry_days}\")\n",
    "print(f\"Median: {median_precip:.2f} in\")\n",
    "print(f\"Mean: {mean_precip:.2f} in\")\n",
    "\n",
    "# Get all rainy day amounts\n",
    "rainy = rainfall[rainfall > 0.5]\n",
    "print(f\"Average rainfall on rainy days: {rainy.mean():.2f} in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Indexing\n",
    "\n",
    "### 7.1 Fancy Indexing: Using Arrays as Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simple array\n",
    "x = np.array([51, 92, 14, 71, 60, 20, 82, 86, 74, 74])\n",
    "\n",
    "# Select specific elements by index\n",
    "ind = [3, 7, 4]\n",
    "print(x[ind])  # [71 86 60]\n",
    "\n",
    "# 2D indexing\n",
    "X = np.arange(12).reshape((3, 4))\n",
    "print(X)\n",
    "# [[ 0  1  2  3]\n",
    "#  [ 4  5  6  7]\n",
    "#  [ 8  9 10 11]]\n",
    "\n",
    "# Select specific rows and columns\n",
    "row = np.array([0, 1, 2])\n",
    "col = np.array([2, 1, 3])\n",
    "print(X[row, col])  # [ 2  5 11]\n",
    "\n",
    "# Select a subset of rows\n",
    "print(X[[0, 2]])\n",
    "# [[ 0  1  2  3]\n",
    "#  [ 8  9 10 11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Modifying Values with Fancy Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Start with array of zeros\n",
    "x = np.zeros(10)\n",
    "print(x)  # [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "\n",
    "# Set specific indices\n",
    "ind = [0, 3, 5]\n",
    "x[ind] = 99\n",
    "print(x)  # [99.  0.  0. 99.  0. 99.  0.  0.  0.  0.]\n",
    "\n",
    "# Increment specific values\n",
    "x[ind] += 1\n",
    "print(x)  # [100.   0.   0. 100.   0. 100.   0.   0.   0.   0.]\n",
    "\n",
    "# Repeated indices - behavior is subtle!\n",
    "x = np.zeros(5)\n",
    "i = [0, 0, 0]\n",
    "x[i] += 1\n",
    "print(x)  # [1. 0. 0. 0. 0.] - only incremented once!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Combined Indexing: Mix and Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 2D array\n",
    "X = np.arange(12).reshape((3, 4))\n",
    "print(X)\n",
    "# [[ 0  1  2  3]\n",
    "#  [ 4  5  6  7]\n",
    "#  [ 8  9 10 11]]\n",
    "\n",
    "# Fancy indexing + slicing\n",
    "# Select rows 0 and 2, columns 1 and 3\n",
    "result = X[[0, 2]][:, [1, 3]]\n",
    "print(result)\n",
    "# [[ 1  3]\n",
    "#  [ 9 11]]\n",
    "\n",
    "# Boolean mask + fancy indexing\n",
    "mask = X[:, 1] > 5\n",
    "print(mask)  # [False False  True]\n",
    "print(X[mask])\n",
    "# [[ 8  9 10 11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sorting\n",
    "\n",
    "### 8.1 Sorting Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Unsorted array\n",
    "x = np.array([2, 1, 4, 3, 5])\n",
    "\n",
    "# Sort (returns new sorted array)\n",
    "print(np.sort(x))  # [1 2 3 4 5]\n",
    "\n",
    "# argsort: returns indices that would sort the array\n",
    "i = np.argsort(x)\n",
    "print(i)  # [1 0 3 2 4]\n",
    "print(x[i])  # [1 2 3 4 5]\n",
    "\n",
    "# Sort in descending order\n",
    "print(x[np.argsort(x)[::-1]])  # [5 4 3 2 1]\n",
    "\n",
    "# Sort 2D array along axis\n",
    "np.random.seed(42)\n",
    "X = np.random.randint(0, 10, (4, 6))\n",
    "print(X)\n",
    "\n",
    "# Sort each column\n",
    "print(np.sort(X, axis=0))\n",
    "\n",
    "# Sort each row\n",
    "print(np.sort(X, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Practical Sorting: Finding Top N Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Array of values\n",
    "x = np.array([7, 2, 3, 1, 6, 5, 4])\n",
    "\n",
    "# Partition: smallest 3 on left, rest on right\n",
    "print(np.partition(x, 3))\n",
    "# [2 1 3 4 6 5 7] (3 smallest values on left, not sorted)\n",
    "\n",
    "# Get indices for partition\n",
    "i = np.argpartition(x, 3)\n",
    "print(x[i])\n",
    "# [2 1 3 4 6 5 7]\n",
    "\n",
    "# Find top K values efficiently\n",
    "# Partition so K largest are on the right\n",
    "K = 3\n",
    "partitioned = np.partition(x, -K)\n",
    "print(partitioned[-K:])  # [5 6 7] (not necessarily sorted)\n",
    "\n",
    "# For sorted top K, use argsort\n",
    "top_k_sorted = x[np.argsort(x)[-K:]]\n",
    "print(top_k_sorted)  # [5 6 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Structured Data in NumPy\n",
    "\n",
    "### 9.1 Structured Arrays: Mixing Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create structured array for person data\n",
    "data = np.zeros(4, dtype={\n",
    "    'names': ('name', 'age', 'weight'),\n",
    "    'formats': ('U10', 'i4', 'f8')\n",
    "})\n",
    "\n",
    "# Fill data\n",
    "data['name'] = ['Alice', 'Bob', 'Cathy', 'Doug']\n",
    "data['age'] = [25, 45, 37, 19]\n",
    "data['weight'] = [55.0, 85.5, 68.0, 61.5]\n",
    "\n",
    "print(data)\n",
    "# [('Alice', 25, 55. ) ('Bob', 45, 85.5)\n",
    "#  ('Cathy', 37, 68. ) ('Doug', 19, 61.5)]\n",
    "\n",
    "# Access by field name\n",
    "print(data['name'])  # ['Alice' 'Bob' 'Cathy' 'Doug']\n",
    "print(data['age'])   # [25 45 37 19]\n",
    "\n",
    "# Filter\n",
    "print(data[data['age'] < 30]['name'])  # ['Alice' 'Doug']"
   ]
  },
  {
   "cell_type": "code",
   "source": "## Summary\n\nThis notebook covered the fundamental concepts of NumPy and Pandas for numerical computing and data manipulation:\n\n### NumPy (Sections 1-9):\n1. **Introduction to NumPy** - Understanding speed advantages and basic arrays\n2. **Array Fundamentals** - Creating, indexing, reshaping, and combining arrays\n3. **Array Operations** - Vectorized arithmetic and universal functions\n4. **Aggregations** - Statistical operations and the axis parameter\n5. **Broadcasting** - Operations on different array shapes\n6. **Boolean Operations** - Masking and filtering data\n7. **Advanced Indexing** - Fancy indexing for complex selections\n8. **Sorting** - Organizing and finding top elements\n9. **Structured Arrays** - Mixing data types\n\n### Pandas (Sections 10-16):\n10. **Introduction to Pandas** - DataFrames and why Pandas matters\n11. **Pandas Core Objects** - Series, DataFrame, and Index\n12. **Data Indexing and Selection** - loc, iloc, and boolean masking\n13. **Operations in Pandas** - Index alignment and ufuncs\n14. **Handling Missing Data** - Detecting, dropping, and filling NaN values\n15. **Hierarchical Indexing** - MultiIndex for higher-dimensional data\n16. **Combining Datasets** - concat and append operations\n\n### Key Takeaways:\n- **NumPy** is 10-100x faster than Python lists for numerical operations\n- Use vectorized operations instead of loops\n- Broadcasting enables operations on different shapes without copying data\n- **Pandas** builds on NumPy to provide labeled, structured data with DataFrames\n- Index alignment automatically handles mismatched data\n- Missing data handling is built into Pandas\n- MultiIndex enables working with higher-dimensional data efficiently\n\n### Next Steps:\n- **Week 5**: Advanced Pandas (merge, join, groupby, pivot tables)\n- **Visualization**: Matplotlib for data visualization\n- **Applications**: Real-world data analysis in civil engineering\n\n---\n\n**Congratulations!** You now have the foundational tools for numerical computing and data analysis in Python. These skills form the basis for all data science work in civil engineering and beyond.",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 16. Combining Datasets: Concat and Append\n\nPandas provides tools to combine data from multiple sources.\n\n### 16.1 Using pd.concat()",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create MultiIndex Series\nindex = pd.MultiIndex.from_tuples([\n    ('California', 2000), ('California', 2010),\n    ('New York', 2000), ('New York', 2010),\n    ('Texas', 2000), ('Texas', 2010)\n])\npopulations = [33871648, 37253956, 18976457,\n               19378102, 20851820, 25145561]\npop = pd.Series(populations, index=index)\npop.index.names = ['state', 'year']\n\nprint(\"MultiIndex Series:\")\nprint(pop)\nprint()\n\n# Access all data for year 2010\nprint(\"All states in 2010:\")\nprint(pop[:, 2010])\nprint()\n\n# Access all data for California\nprint(\"California across years:\")\nprint(pop['California'])\nprint()\n\n# Unstack: convert to regular DataFrame\nprint(\"Unstacked (MultiIndex → DataFrame):\")\nprint(pop.unstack())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 15. Hierarchical Indexing (MultiIndex)\n\nMultiIndex allows you to store higher-dimensional data in 1D Series or 2D DataFrames.\n\n### 15.1 Creating and Using MultiIndex",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create data with missing values\ndata = pd.Series([1, np.nan, 'hello', None])\nprint(\"Data with missing values:\")\nprint(data)\nprint()\n\n# Detect missing values\nprint(\"isnull():\")\nprint(data.isnull())\nprint()\n\n# Drop missing values\nprint(\"dropna():\")\nprint(data.dropna())\nprint()\n\n# Fill missing values\ndata_numeric = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\nprint(\"Original data:\")\nprint(data_numeric)\nprint()\n\nprint(\"fillna(0):\")\nprint(data_numeric.fillna(0))\nprint()\n\nprint(\"fillna(method='ffill') - forward fill:\")\nprint(data_numeric.fillna(method='ffill'))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 14. Handling Missing Data\n\nReal-world data is rarely clean! Pandas provides tools to detect, remove, and fill missing data.\n\n### 14.1 Detecting and Handling Missing Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# NumPy ufuncs preserve index!\nrng = np.random.RandomState(42)\nser = pd.Series(rng.randint(0, 10, 4))\nprint(\"Original Series:\")\nprint(ser)\nprint()\n\nprint(\"np.exp(ser) - index preserved:\")\nprint(np.exp(ser))\nprint()\n\n# Index Alignment: Operations align on matching indices\narea_top3 = pd.Series({'Alaska': 1723337, 'Texas': 695662,\n                       'California': 423967})\npop_top3 = pd.Series({'California': 38332521, 'Texas': 26448193,\n                      'New York': 19651127})\n\n# Division aligns indices automatically!\ndensity = pop_top3 / area_top3\nprint(\"Automatic index alignment:\")\nprint(density)\nprint(\"\\nNote: NaN where indices don't match!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 13. Operations in Pandas\n\nPandas inherits NumPy's ufuncs but adds two powerful features:\n1. **Index Preservation**: Labels are maintained through operations\n2. **Index Alignment**: Operations automatically align on matching indices\n\n### 13.1 Ufuncs with Index Preservation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# loc: Label-based indexing\nprint(\"Using loc (label-based):\")\nprint(\"First 3 rows, first 2 columns:\")\nprint(states.loc[:'Florida', :'area'])\nprint()\n\n# iloc: Integer-based indexing\nprint(\"Using iloc (integer-based):\")\nprint(\"First 3 rows, first 2 columns:\")\nprint(states.iloc[:3, :2])\nprint()\n\n# Boolean masking\nhigh_density = states['density'] > 100\nprint(\"High density states (> 100):\")\nprint(states[high_density])\nprint()\n\n# Combining loc with boolean mask\nprint(\"High density states - only population and density:\")\nprint(states.loc[high_density, ['population', 'density']])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 12. Data Indexing and Selection\n\nPandas provides powerful indexing capabilities through `loc` (label-based) and `iloc` (integer-based) indexers.\n\n### 12.1 The Indexers: loc and iloc",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Multiple ways to create DataFrames\n\n# From dictionary of lists\ndf1 = pd.DataFrame({'A': [1, 2, 3],\n                    'B': [4, 5, 6]})\nprint(\"From dict of lists:\")\nprint(df1)\nprint()\n\n# From list of dictionaries\ndf2 = pd.DataFrame([{'a': 1, 'b': 2},\n                    {'a': 3, 'b': 4, 'c': 5}])\nprint(\"From list of dicts:\")\nprint(df2)\nprint()\n\n# From NumPy array\ndf3 = pd.DataFrame(np.random.rand(3, 2),\n                   columns=['foo', 'bar'],\n                   index=['a', 'b', 'c'])\nprint(\"From NumPy array:\")\nprint(df3)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create DataFrame from dictionary of Series\narea_dict = {'California': 423967, 'Texas': 695662,\n             'New York': 141297, 'Florida': 170312,\n             'Illinois': 149995}\narea = pd.Series(area_dict)\n\nstates = pd.DataFrame({'population': population,\n                       'area': area})\nprint(\"DataFrame from Series:\")\nprint(states)\nprint()\n\nprint(\"Index (row labels):\", states.index.tolist())\nprint(\"Columns:\", states.columns.tolist())\nprint()\n\n# Add new column\nstates['density'] = states['population'] / states['area']\nprint(\"DataFrame with new 'density' column:\")\nprint(states)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 11.2 The DataFrame: 2D Labeled Data Structure",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Series with custom string index (like a dictionary!)\ndata = pd.Series([0.25, 0.5, 0.75, 1.0],\n                 index=['a', 'b', 'c', 'd'])\nprint(\"Series with custom index:\")\nprint(data)\nprint()\n\n# Access by label\nprint(f\"Element 'b': {data['b']}\")\n\n# Series from dictionary\npopulation_dict = {\n    'California': 38332521,\n    'Texas': 26448193,\n    'New York': 19651127,\n    'Florida': 19552860,\n    'Illinois': 12882135\n}\npopulation = pd.Series(population_dict)\nprint(\"\\nSeries from dictionary:\")\nprint(population)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create Series from list\ndata = pd.Series([0.25, 0.5, 0.75, 1.0])\nprint(\"Series with default integer index:\")\nprint(data)\nprint()\n\n# Access values and index\nprint(\"Values:\", data.values)\nprint(\"Index:\", data.index)\nprint()\n\n# Access like array\nprint(\"Element at index 1:\", data[1])\nprint(\"Slice [1:3]:\")\nprint(data[1:3])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Pandas Core Objects\n\nPandas provides three fundamental data structures:\n- **Series**: 1D labeled array (like a column)\n- **DataFrame**: 2D labeled table (like a spreadsheet)\n- **Index**: Row and column labels\n\n### 11.1 The Pandas Series: 1D Labeled Array",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# NumPy array - access by integer index only\ndata_numpy = np.array([[1, 2, 3],\n                       [4, 5, 6]])\nprint(\"NumPy array:\")\nprint(data_numpy)\nprint(f\"Element at [0, 1]: {data_numpy[0, 1]}\")  # 2\nprint(\"Which column is this? Must remember!\\n\")\n\n# Pandas DataFrame - access by label or index\ndf = pd.DataFrame([[1, 2, 3],\n                   [4, 5, 6]],\n                  columns=['A', 'B', 'C'])\nprint(\"Pandas DataFrame:\")\nprint(df)\nprint(f\"\\nElement 'B' in row 0: {df['B'][0]}\")  # 2\nprint(\"Clear what column 'B' means!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 10.1 NumPy vs Pandas: A Quick Comparison",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Standard Import Convention\nimport pandas as pd  # ALWAYS use this convention!\nimport numpy as np   # Often used together\n\n# Check version\nprint(f\"Pandas version: {pd.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 10. Introduction to Pandas\n\nPandas is built on top of NumPy and provides DataFrames - labeled, 2D data structures that are like spreadsheets or SQL tables, but in Python. It's the industry standard for data manipulation and analysis.\n\n### Why Pandas After NumPy?\n- **NumPy**: Fast arrays, but no labels or structure\n- **Pandas**: Labels + missing data + heterogeneous types\n- Access data by name, not just index position\n- Built-in tools for reading CSV, Excel, SQL\n- Better for messy, real-world data",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered the fundamental concepts of NumPy for numerical computing:\n",
    "\n",
    "1. **Introduction to NumPy** - Understanding speed advantages and basic arrays\n",
    "2. **Array Fundamentals** - Creating, indexing, reshaping, and combining arrays\n",
    "3. **Array Operations** - Vectorized arithmetic and universal functions\n",
    "4. **Aggregations** - Statistical operations and the axis parameter\n",
    "5. **Broadcasting** - Operations on different array shapes\n",
    "6. **Boolean Operations** - Masking and filtering data\n",
    "7. **Advanced Indexing** - Fancy indexing for complex selections\n",
    "8. **Sorting** - Organizing and finding top elements\n",
    "9. **Structured Arrays** - Mixing data types (though Pandas is usually better)\n",
    "\n",
    "### Key Takeaways:\n",
    "- NumPy is 10-100x faster than Python lists for numerical operations\n",
    "- Use vectorized operations instead of loops\n",
    "- Broadcasting enables operations on different shapes without copying data\n",
    "- Boolean masking is powerful for filtering data\n",
    "- NumPy is the foundation for the entire PyData ecosystem\n",
    "\n",
    "**Next Week**: We'll explore Pandas, which builds on NumPy to provide DataFrames for structured data analysis with labeled columns and rows!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}